{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce2dcf1d-32b0-44f0-9030-cafc1fa17934",
   "metadata": {},
   "source": [
    "Goals:\n",
    "This notebook attempts to set up a POC for \"Infinite Memory\"\n",
    "1. Store\n",
    "2. Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cc2ac8-5e30-4572-ad81-a3378195b083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import display\n",
    "from loguru import logger\n",
    "from openai import OpenAI\n",
    "from getpass import getpass\n",
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16830702-78af-4883-971d-fccce2c76144",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf0fcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = getpass(\"enter_openai_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0299cbb-e1ff-4804-a1bc-36073f9118b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "from typing import Type, Union, Any\n",
    "from llama_index.core.output_parsers.utils import parse_json_markdown\n",
    "import json\n",
    "\n",
    "openai_client = OpenAI(\n",
    "            api_key=openai_api_key,  \n",
    "        )\n",
    "\n",
    "def make_request(model: str, messages: list[dict[str, str]]) -> str:\n",
    "    start_time = time.time()\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "@retry(\n",
    "    stop=stop_after_attempt(3),\n",
    "    wait=wait_fixed(2),\n",
    ")\n",
    "def chat_completion_request(\n",
    "    messages: list[dict[str, str]],\n",
    "    model: str = \"gpt-4o\",\n",
    "    response_model: Type[BaseModel] = None,\n",
    ") -> Union[str, dict[str, Any]]:\n",
    "    try:\n",
    "        content = make_request(model, messages)\n",
    "        if response_model is not None:\n",
    "            parsed_content = parse_json_markdown(content)\n",
    "            try:\n",
    "                return response_model(**parsed_content)\n",
    "            except TypeError as e:\n",
    "                error_message = {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"JSON decoding error: {e}. Please adhere to the json response format that obeys the following schema: {response_model.model_json_schema()}\",\n",
    "                }\n",
    "                messages.append(error_message)\n",
    "                logger.error(\n",
    "                    f\"TypeError in response_model parsing: {e}. Content: {parsed_content}\"\n",
    "                )\n",
    "                raise\n",
    "        else:\n",
    "            return content\n",
    "    except json.JSONDecodeError as e:\n",
    "        error_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"JSON decoding error: {e}. Please adhere to the json response format that obeys the following schema: {response_model.model_json_schema()}\",\n",
    "        }\n",
    "        messages.append(error_message)\n",
    "        logger.error(f\"JSON decoding error: {e}. Content: {content}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error while making chat completion request: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d650a3c-0abe-4184-8ed2-4e21fbc837ea",
   "metadata": {},
   "source": [
    "# Intialize DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18d9996b-7900-482c-9b7f-d07b8546f847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.EphemeralClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7008032d-d6b8-4079-ab49-7fef5ce0194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "\n",
    "class CustomOpenAIEmbeddingFunction(EmbeddingFunction):\n",
    "    def __call__(self, input: list[str]) -> Embeddings:\n",
    "        input = [text.replace(\"\\n\", \" \") for text in input]\n",
    "        emb_resp = openai_client.embeddings.create(input=input, model='text-embedding-3-small').data\n",
    "        return [emb.embedding for emb in emb_resp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25ac1b1e-3ea7-44cf-bc88-64cdc9f2be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.get_or_create_collection(name=\"user_history\", embedding_function=CustomOpenAIEmbeddingFunction()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2692de8e-855f-4249-b771-28de4dda34d8",
   "metadata": {},
   "source": [
    "# Create functions to add, delete and query DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d627b1eb-4e17-4a9e-9e17-8111a9a72cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Delete of nonexisting embedding ID: ce617a99-cc06-478c-9ddb-7f041572a139\n",
      "Delete of nonexisting embedding ID: b5c1f87b-3e66-4dd0-8bcf-02b6d523a74c\n",
      "Delete of nonexisting embedding ID: ce617a99-cc06-478c-9ddb-7f041572a139\n",
      "Delete of nonexisting embedding ID: b5c1f87b-3e66-4dd0-8bcf-02b6d523a74c\n"
     ]
    }
   ],
   "source": [
    "# deleting\n",
    "def delete_from_index(collection, ids):\n",
    "    collection.delete(\n",
    "        ids=ids\n",
    "    )\n",
    "delete_from_index(collection=collection,ids=['ce617a99-cc06-478c-9ddb-7f041572a139',\n",
    "  'b5c1f87b-3e66-4dd0-8bcf-02b6d523a74c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af945109-33c1-4713-b88d-fdbd9612633e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-20 23:09:21.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minsert_to_index\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mSuccessfully inserted 2 documents\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "# inserting\n",
    "def insert_to_index(collection, documents, metadatas=None):\n",
    "    collection.add(\n",
    "        documents=documents,\n",
    "        metadatas=metadatas,\n",
    "        ids=[str(uuid.uuid4()) for i in range(len(documents))],\n",
    "    )\n",
    "    logger.info(f\"Successfully inserted {len(documents)} documents\")\n",
    "\n",
    "insert_to_index(collection=collection, documents=['Fu Nan is a boy', 'Jane is a girl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b5b668c-e12b-4b39-b144-2d72062d093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryResult(BaseModel):\n",
    "    ids: list[list[str]]\n",
    "    documents: list[list[str]]\n",
    "    distances: list[list[float]]\n",
    "\n",
    "# querying https://docs.trychroma.com/guides#filtering-by-metadata\n",
    "def query_index(query_texts, n_results=1, where=None, where_document=None):\n",
    "    query_result = collection.query(\n",
    "        query_texts=query_texts,\n",
    "        n_results=n_results,\n",
    "        where=where,\n",
    "        where_document=where_document,\n",
    "    )\n",
    "    return QueryResult(**query_result)\n",
    "    \n",
    "query_result = query_index(\n",
    "    query_texts=[\"female\", \"male\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc02dd1-cf8e-4a31-b93a-0455890f8428",
   "metadata": {},
   "source": [
    "# /Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37a6205",
   "metadata": {},
   "source": [
    "## extract_snippets_from_conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b35212f-30f0-4046-9bd5-1ab77833e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class Snippet(BaseModel):\n",
    "    text: str\n",
    "    date_of_event: Optional[str] = Field(description=\"to be filled in if the snippet is an event\", default=None) # TODO not sure what to do with this info for now\n",
    "\n",
    "class ConversationSnippets(BaseModel):\n",
    "    snippets: list[Snippet]\n",
    "\n",
    "extract_snippets_from_conversation_prompt = \"\"\"\\\n",
    "You are to extract snippets of a given conversation between a career confidante and a user, which the confidante should take node of. Think of it as the confidante jotting key points down during the conversation in their journal.\n",
    "Each snippet has to contain sufficient information to stand alone and be understood without the context of the entire conversation.\n",
    "\n",
    "**\n",
    "IMPORTANT: Only return the output in JSON format. The JSON structure should be a list of snippet objects, each with the fields:\n",
    "\t•\t\"text\" (str): The extracted text snippet from the conversation.\n",
    "\t•\t\"date_of_event\" (string): The date of the event mentioned in the snippet. If the snippet is not about an event, this field should be null. Date shouuld be formatted as \"YYYY-MM-DD\".\n",
    "\n",
    "Example conversation that happend on 2024-02-01:\n",
    "User: I am a software engineer and I am considering a career change.\n",
    "Confidante: What are you considering?\n",
    "User: I am considering becoming a data scientist.\n",
    "Confidante: What is motivating you to make this change?\n",
    "User: I am interested in working with data and I want to leverage my programming skills. I am also going to start taking a course in data science.\n",
    "Confidante: That's awesome, when do you plan to start the course?\n",
    "User: I plan to start next month.\n",
    "Confidante: Great!\n",
    "\n",
    "Example JSON:\n",
    "{{\n",
    "    \"snippets\": [\n",
    "        {{\n",
    "            \"text\": \"User is considering becoming a data scientist.\",\n",
    "            \"date_of_event\": null\n",
    "        }},\n",
    "        {{\n",
    "            \"text\": \"User is interested in working with data and wants to leverage programming skills. User is also going to start taking a course in data science.\",\n",
    "            \"date_of_event\": null\n",
    "        }},\n",
    "        {{\n",
    "            \"text\": \"User plans to start data science course next month.\",\n",
    "            \"date_of_event\": \"2024-03-01\"\n",
    "        }}\n",
    "\n",
    "    ]\n",
    "}}\n",
    "===== END OF EXAMPLE ======\n",
    "\n",
    "The 'snippets' key must be a list of snippets.\n",
    "The result must be a list of objects with 'text' and 'date_of_event' keys.\n",
    "Ensure each snippet contains sufficient information to stand alone and be understood without the context of the entire conversation.\n",
    "**\n",
    "\n",
    "Conversation that happened on {date}:\n",
    "{conversation}\n",
    "\n",
    "JSON:\n",
    "\"\"\"\n",
    "\n",
    "def _get_date_today():\n",
    "    return datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def _construct_conversation(user_messages:list[str], assistant_messages:list[str])->str:\n",
    "    conversation = []\n",
    "    for user_message, assistant_message in zip(user_messages, assistant_messages):\n",
    "        conversation.append(f\"User: {user_message}\")\n",
    "        conversation.append(f\"Confidante: {assistant_message}\")\n",
    "    return \"\\n\".join(conversation)\n",
    "\n",
    "def extract_snippets_from_conversation(user_messages:list[str], assistant_messages:list[str]):\n",
    "    conversation = _construct_conversation(user_messages, assistant_messages)\n",
    "    prompt = extract_snippets_from_conversation_prompt.format(date=_get_date_today(), conversation=conversation)\n",
    "    conversation_snippets: ConversationSnippets = chat_completion_request(\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_model=ConversationSnippets\n",
    "    )\n",
    "    logger.info(f\"Successfully extracted {len(conversation_snippets.snippets)} snippets from conversation\")\n",
    "    return conversation_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "264acf22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationSnippets(snippets=[Snippet(text='User just got laid off from their job.', date_of_event=None), Snippet(text='User is considering a career change.', date_of_event=None), Snippet(text='User is thinking of starting a course in data science.', date_of_event=None), Snippet(text='User plans to start the data science course tomorrow.', date_of_event='2024-11-21')])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test case\n",
    "test_snippets = extract_snippets_from_conversation(\n",
    "    user_messages=[\"I just got laid off from my job.\", \"I am considering a career change.\", \"First, I am thinking of starting a course in data science.\", \"tomorrow\"],\n",
    "    assistant_messages=[\"What are you considering?\", \"What are your interests?\", \"When do you plan to start the course?\", \"That's great!\"]\n",
    ")\n",
    "test_snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753a1a8d",
   "metadata": {},
   "source": [
    "## Insert snippets to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d976e048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-20 23:15:56.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minsert_to_index\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mSuccessfully inserted 4 documents\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# insert to index\n",
    "def insert_snippets_to_index(collection, conversation_snippets: ConversationSnippets):\n",
    "    insert_to_index(\n",
    "        collection=collection, \n",
    "        documents=[snippet.text for snippet in conversation_snippets.snippets], \n",
    "        metadatas=[{\"date_of_event\": snippet.date_of_event} if snippet.date_of_event else {\"date_of_evebt\": \"\"} for snippet in conversation_snippets.snippets]\n",
    "    )\n",
    "        \n",
    "insert_snippets_to_index(collection=collection, conversation_snippets=test_snippets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc6cf840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection.peek()['documents']\n",
    "# collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f4bef6-98a8-42cb-bd80-0fd2b3fc7f70",
   "metadata": {},
   "source": [
    "## [to be done] Deduplicating/Updating snippets against content in index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c1cbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentNode(BaseModel):\n",
    "    id: str\n",
    "    document: str    \n",
    "\n",
    "class SnippetsWithContext(BaseModel):\n",
    "    snippet: str\n",
    "    context: list[DocumentNode]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc196d3-f429-4ae1-9c3f-664aab0afd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from datetime import datetime\n",
    "\n",
    "class Snippet(BaseModel):\n",
    "    snippet: str\n",
    "    date_of_event: Optional[str] = Field(description=\"to be filled in if the snippet is an event\", default=None)\n",
    "\n",
    "class ConversationSnippets(BaseModel):\n",
    "    snippets: list[Snippet]\n",
    "\n",
    "extract_snippets_from_conversation_prompt = \"\"\"\\\n",
    "You are to extract snippets of a given conversation between a career confidante and a user, which the confidante should take node of. Think of it as the confidante jotting key points down during the conversation in their journal.\n",
    "Each snippet has to contain sufficient information to stand alone and be understood without the context of the entire conversation.\n",
    "\n",
    "**\n",
    "IMPORTANT: Only return the output in JSON format. The JSON structure should be a list of snippet objects, each with the fields:\n",
    "\t•\t\"snippet\" (str): The extracted snippet from the conversation.\n",
    "\t•\t\"date_of_event\" (string): The date of the event mentioned in the snippet. If the snippet is not about an event, this field should be null. Date shouuld be formatted as \"YYYY-MM-DD\".\n",
    "\n",
    "Example conversation that happend on 2024-02-01:\n",
    "User: I am a software engineer and I am considering a career change.\n",
    "Confidante: What are you considering?\n",
    "User: I am considering becoming a data scientist.\n",
    "Confidante: What is motivating you to make this change?\n",
    "User: I am interested in working with data and I want to leverage my programming skills. I am also going to start taking a course in data science.\n",
    "Confidante: That's awesome, when do you plan to start the course?\n",
    "User: I plan to start next month.\n",
    "Confidante: Great!\n",
    "\n",
    "Example JSON:\n",
    "{{\n",
    "    \"snippets\": [\n",
    "        {{\n",
    "            \"snippet\": \"User is considering becoming a data scientist.\",\n",
    "            \"date_of_event\": null\n",
    "        }},\n",
    "        {{\n",
    "            \"snippet\": \"User is interested in working with data and wants to leverage programming skills. User is also going to start taking a course in data science.\",\n",
    "            \"date_of_event\": null\n",
    "        }},\n",
    "        {{\n",
    "            \"snippet\": \"User plans to start data science course next month.\",\n",
    "            \"date_of_event\": \"2024-03-01\"\n",
    "        }}\n",
    "\n",
    "    ]\n",
    "}}\n",
    "===== END OF EXAMPLE ======\n",
    "\n",
    "The 'snippets' key must be a list of snippets.\n",
    "The result must be a list of objects with 'snippet' and 'date_of_event' keys.\n",
    "Ensure each snippet contains sufficient information to stand alone and be understood without the context of the entire conversation.\n",
    "**\n",
    "\n",
    "Conversation that happened on {date}:\n",
    "{conversation}\n",
    "\n",
    "JSON:\n",
    "\"\"\"\n",
    "\n",
    "def determine_snippets_to_add_or_delete():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc54838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_documents_from_index():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75c5f62-44d0-4dd5-83de-59a0833130ec",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aed1c73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store(user_messages:list[str], assistant_messages:list[str]):\n",
    "    conversation_snippets = extract_snippets_from_conversation(\n",
    "        user_messages=user_messages,\n",
    "        assistant_messages=assistant_messages\n",
    "    )\n",
    "    # determine_snippets_to_add_or_delete()\n",
    "    # delete_documents_from_index()\n",
    "    insert_snippets_to_index(collection=collection, conversation_snippets=conversation_snippets)\n",
    "    logger.info(f\"There are now {collection.count()} documents in the index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68f4c54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-20 23:22:24.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mextract_snippets_from_conversation\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1mSuccessfully extracted 4 snippets from conversation\u001b[0m\n",
      "\u001b[32m2024-11-20 23:22:25.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minsert_to_index\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mSuccessfully inserted 4 documents\u001b[0m\n",
      "\u001b[32m2024-11-20 23:22:25.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mstore\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mThere are now 20 documents in the index\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "store(\n",
    "    user_messages=[\"I just got laid off from my job.\", \"I am considering a career change.\", \"First, I am thinking of starting a course in data science.\", \"tomorrow\"],\n",
    "    assistant_messages=[\"What are you considering?\", \"What are your interests?\", \"When do you plan to start the course?\", \"That's great!\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652929dd-cbc8-4230-ac35-0d035696c4a9",
   "metadata": {},
   "source": [
    "# /Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1264c05e-808d-4c7b-9c8d-22fdb88651e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_DISTANCE=1.3\n",
    "K=10\n",
    "\n",
    "def _build_context(query_result: QueryResult, min_distance:float)->str:\n",
    "    documents = query_result.documents[0]\n",
    "    distances = query_result.distances[0]\n",
    "    context = [\"Here are some notes from previous conversations between you and the user that might be relevant to you. Note that this snippets are from conversations that happened in the past.\"]\n",
    "    context_num = 1\n",
    "    seen_contexts = set() # to handle exact duplicates that could inadvertedly be in the index\n",
    "    for document, distance in zip(documents, distances):\n",
    "        if distance < min_distance and document not in seen_contexts:\n",
    "            context.append(f\"{context_num}: {document}\")\n",
    "            context_num += 1\n",
    "            seen_contexts.add(document)\n",
    "    return \"\\n\".join(context)\n",
    "\n",
    "\n",
    "def retrieve(content_to_retrieve:str, min_distance:float=MIN_DISTANCE, k:int=K):\n",
    "    query_result = query_index(\n",
    "        query_texts=[content_to_retrieve],\n",
    "        n_results=k\n",
    "    )\n",
    "    return _build_context(query_result, min_distance)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d77db495-2404-479d-bcd4-a8a09e8d18bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some notes from previous conversations between you and the user that might be relevant to you. Note that this snippets are from conversations that happened in the past.\n",
      "1: User is thinking of starting a course in data science.\n",
      "2: User plans to start the data science course tomorrow.\n",
      "3: User is considering a career change.\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "retrieval_result = retrieve(\"when is the user going to start a course?\")\n",
    "print(retrieval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bb7877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
