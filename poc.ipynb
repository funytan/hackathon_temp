{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce2dcf1d-32b0-44f0-9030-cafc1fa17934",
   "metadata": {},
   "source": [
    "Goals:\n",
    "This notebook attempts to set up a POC for \"Infinite Memory\"\n",
    "1. Store\n",
    "2. Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "31cc2ac8-5e30-4572-ad81-a3378195b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import display\n",
    "from loguru import logger\n",
    "from openai import OpenAI\n",
    "from getpass import getpass\n",
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16830702-78af-4883-971d-fccce2c76144",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c66cab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = getpass(\"enter_openai_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0299cbb-e1ff-4804-a1bc-36073f9118b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "from typing import Type, Union, Any\n",
    "from llama_index.core.output_parsers.utils import parse_json_markdown\n",
    "import json\n",
    "\n",
    "openai_client = OpenAI(\n",
    "            api_key=openai_api_key,  \n",
    "        )\n",
    "\n",
    "def make_request(model: str, messages: list[dict[str, str]]) -> str:\n",
    "    start_time = time.time()\n",
    "    if model == \"gpt-4o\":\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0,\n",
    "        )\n",
    "    elif model == \"o1-preview\":\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid model: {model}\")\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "@retry(\n",
    "    stop=stop_after_attempt(3),\n",
    "    wait=wait_fixed(2),\n",
    ")\n",
    "def chat_completion_request(\n",
    "    messages: list[dict[str, str]],\n",
    "    model: str = \"gpt-4o\",\n",
    "    response_model: Type[BaseModel] = None,\n",
    ") -> Union[str, dict[str, Any]]:\n",
    "    try:\n",
    "        content = make_request(model, messages)\n",
    "        if response_model is not None:\n",
    "            parsed_content = parse_json_markdown(content)\n",
    "            try:\n",
    "                return response_model(**parsed_content)\n",
    "            except TypeError as e:\n",
    "                error_message = {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"JSON decoding error: {e}. Please adhere to the json response format that obeys the following schema: {response_model.model_json_schema()}\",\n",
    "                }\n",
    "                messages.append(error_message)\n",
    "                logger.error(\n",
    "                    f\"TypeError in response_model parsing: {e}. Content: {parsed_content}\"\n",
    "                )\n",
    "                raise\n",
    "        else:\n",
    "            return content\n",
    "    except json.JSONDecodeError as e:\n",
    "        error_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"JSON decoding error: {e}. Please adhere to the json response format that obeys the following schema: {response_model.model_json_schema()}\",\n",
    "        }\n",
    "        messages.append(error_message)\n",
    "        logger.error(f\"JSON decoding error: {e}. Content: {content}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error while making chat completion request: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d650a3c-0abe-4184-8ed2-4e21fbc837ea",
   "metadata": {},
   "source": [
    "# Intialize Memory - DB and Chat Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8814cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "class CurrentKnowledge(BaseModel):\n",
    "    knowledge: Optional[str] = Field(description=\"The current knowledge of the user\", default=None)\n",
    "\n",
    "current_knowledge = CurrentKnowledge(knowledge='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d9996b-7900-482c-9b7f-d07b8546f847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.EphemeralClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7008032d-d6b8-4079-ab49-7fef5ce0194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "\n",
    "class CustomOpenAIEmbeddingFunction(EmbeddingFunction):\n",
    "    def __call__(self, input: list[str]) -> Embeddings:\n",
    "        input = [text.replace(\"\\n\", \" \") for text in input]\n",
    "        emb_resp = openai_client.embeddings.create(input=input, model='text-embedding-3-small').data\n",
    "        return [emb.embedding for emb in emb_resp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ac1b1e-3ea7-44cf-bc88-64cdc9f2be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.get_or_create_collection(name=\"user_history\", embedding_function=CustomOpenAIEmbeddingFunction()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2692de8e-855f-4249-b771-28de4dda34d8",
   "metadata": {},
   "source": [
    "# Create functions to add, delete and query DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d627b1eb-4e17-4a9e-9e17-8111a9a72cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Delete of nonexisting embedding ID: ce617a99-cc06-478c-9ddb-7f041572a139\n",
      "Delete of nonexisting embedding ID: b5c1f87b-3e66-4dd0-8bcf-02b6d523a74c\n",
      "Delete of nonexisting embedding ID: ce617a99-cc06-478c-9ddb-7f041572a139\n",
      "Delete of nonexisting embedding ID: b5c1f87b-3e66-4dd0-8bcf-02b6d523a74c\n"
     ]
    }
   ],
   "source": [
    "# deleting\n",
    "def delete_from_index(collection, ids):\n",
    "    collection.delete(\n",
    "        ids=ids\n",
    "    )\n",
    "delete_from_index(collection=collection,ids=['ce617a99-cc06-478c-9ddb-7f041572a139',\n",
    "  'b5c1f87b-3e66-4dd0-8bcf-02b6d523a74c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af945109-33c1-4713-b88d-fdbd9612633e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "insert_to_index() missing 1 required positional argument: 'ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[127], line 11\u001b[0m\n\u001b[1;32m      4\u001b[0m     collection\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m      5\u001b[0m         documents\u001b[38;5;241m=\u001b[39mdocuments,\n\u001b[1;32m      6\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[1;32m      7\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully inserted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(documents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m documents\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43minsert_to_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFu Nan is a boy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mJane is a girl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: insert_to_index() missing 1 required positional argument: 'ids'"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "# inserting\n",
    "def insert_to_index(collection, documents, ids, metadatas=None):\n",
    "    collection.add(\n",
    "        documents=documents,\n",
    "        metadatas=metadatas,\n",
    "        ids=ids,\n",
    "    )\n",
    "    logger.info(f\"Successfully inserted {len(documents)} documents\")\n",
    "\n",
    "insert_to_index(collection=collection, documents=['Fu Nan is a boy', 'Jane is a girl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1b5b668c-e12b-4b39-b144-2d72062d093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryResult(BaseModel):\n",
    "    ids: list[list[str]]\n",
    "    documents: list[list[str]]\n",
    "    distances: list[list[float]]\n",
    "    metadatas: list[list[Optional[dict[str, str]]]]\n",
    "\n",
    "# querying https://docs.trychroma.com/guides#filtering-by-metadata\n",
    "def query_index(query_texts, n_results=1, where=None, where_document=None):\n",
    "    query_result = collection.query(\n",
    "        query_texts=query_texts,\n",
    "        n_results=n_results,\n",
    "        where=where,\n",
    "        where_document=where_document,\n",
    "    )\n",
    "    return QueryResult(**query_result)\n",
    "    \n",
    "query_result = query_index(\n",
    "    query_texts=[\"female\", \"male\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f877fcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_index(ids, documents, metadatas=None):\n",
    "    collection.update(\n",
    "        ids=ids,\n",
    "        metadatas=metadatas,\n",
    "        documents=documents,\n",
    "    )\n",
    "    logger.info(f\"Successfully updated {len(ids)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc02dd1-cf8e-4a31-b93a-0455890f8428",
   "metadata": {},
   "source": [
    "# /Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37a6205",
   "metadata": {},
   "source": [
    "## extract_snippets_from_conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b35212f-30f0-4046-9bd5-1ab77833e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class Snippet(BaseModel):\n",
    "    text: str\n",
    "    date_of_event: Optional[str] = Field(description=\"to be filled in if the snippet is an event\", default=None) # TODO not sure what to do with this info for now\n",
    "    id: Optional[str] = Field(description=\"id of the snippet\", default=None)\n",
    "\n",
    "class ConversationSnippets(BaseModel):\n",
    "    snippets: list[Snippet]\n",
    "\n",
    "extract_snippets_from_conversation_prompt = \"\"\"\\\n",
    "You are to extract snippets of a given conversation between a career confidante and a user, which the confidante should take node of. Think of it as the confidante jotting key points down during the conversation in their journal.\n",
    "Each snippet has to contain sufficient information to stand alone and be understood without the context of the entire conversation.\n",
    "\n",
    "**\n",
    "IMPORTANT: Only return the output in JSON format. The JSON structure should be a list of snippet objects, each with the fields:\n",
    "\t•\t\"text\" (str): The extracted text snippet from the conversation.\n",
    "\t•\t\"date_of_event\" (string): The date of the event mentioned in the snippet. If the snippet is not about an event, this field should be null. Date shouuld be formatted as \"YYYY-MM-DD\".\n",
    "\n",
    "Example conversation that happend on 2024-02-01:\n",
    "User: I am a software engineer and I am considering a career change.\n",
    "Confidante: What are you considering?\n",
    "User: I am considering becoming a data scientist.\n",
    "Confidante: What is motivating you to make this change?\n",
    "User: I am interested in working with data and I want to leverage my programming skills. I am also going to start taking a course in data science.\n",
    "Confidante: That's awesome, when do you plan to start the course?\n",
    "User: I plan to start next month.\n",
    "Confidante: Great!\n",
    "\n",
    "Example JSON:\n",
    "{{\n",
    "    \"snippets\": [\n",
    "        {{\n",
    "            \"text\": \"User is considering becoming a data scientist.\",\n",
    "            \"date_of_event\": null\n",
    "        }},\n",
    "        {{\n",
    "            \"text\": \"User is interested in working with data and wants to leverage programming skills. User is also going to start taking a course in data science.\",\n",
    "            \"date_of_event\": null\n",
    "        }},\n",
    "        {{\n",
    "            \"text\": \"User plans to start data science course next month.\",\n",
    "            \"date_of_event\": \"2024-03-01\"\n",
    "        }}\n",
    "\n",
    "    ]\n",
    "}}\n",
    "===== END OF EXAMPLE ======\n",
    "\n",
    "The 'snippets' key must be a list of snippets.\n",
    "The result must be a list of objects with 'text' and 'date_of_event' keys.\n",
    "Ensure each snippet contains sufficient information to stand alone and be understood without the context of the entire conversation.\n",
    "**\n",
    "\n",
    "Conversation that happened on {date}:\n",
    "{conversation}\n",
    "\n",
    "JSON:\n",
    "\"\"\"\n",
    "\n",
    "def _get_date_today():\n",
    "    return datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def _construct_conversation(user_messages:list[str], assistant_messages:list[str])->str:\n",
    "    conversation = []\n",
    "    for user_message, assistant_message in zip(user_messages, assistant_messages):\n",
    "        conversation.append(f\"User: {user_message}\")\n",
    "        conversation.append(f\"Confidante: {assistant_message}\")\n",
    "    return \"\\n\".join(conversation)\n",
    "\n",
    "def extract_snippets_from_conversation(user_messages:list[str], assistant_messages:list[str]):\n",
    "    conversation = _construct_conversation(user_messages, assistant_messages)\n",
    "    prompt = extract_snippets_from_conversation_prompt.format(date=_get_date_today(), conversation=conversation)\n",
    "    conversation_snippets: ConversationSnippets = chat_completion_request(\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_model=ConversationSnippets\n",
    "    )\n",
    "    logger.info(f\"Successfully extracted {len(conversation_snippets.snippets)} snippets from conversation\")\n",
    "    return conversation_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264acf22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationSnippets(snippets=[Snippet(text='User just got laid off from their job.', date_of_event=None), Snippet(text='User is considering a career change.', date_of_event=None), Snippet(text='User is thinking of starting a course in data science.', date_of_event=None), Snippet(text='User plans to start the data science course tomorrow.', date_of_event='2024-11-21')])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test case\n",
    "test_snippets = extract_snippets_from_conversation(\n",
    "    user_messages=[\"I just got laid off from my job.\", \"I am considering a career change.\", \"First, I am thinking of starting a course in data science.\", \"tomorrow\"],\n",
    "    assistant_messages=[\"What are you considering?\", \"What are your interests?\", \"When do you plan to start the course?\", \"That's great!\"]\n",
    ")\n",
    "test_snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753a1a8d",
   "metadata": {},
   "source": [
    "## Insert snippets to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d976e048",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Snippet' object has no attribute 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[172], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minsert_snippets_to_index\u001b[39m(collection, conversation_snippets: ConversationSnippets):\n\u001b[1;32m      3\u001b[0m     insert_to_index(\n\u001b[1;32m      4\u001b[0m         collection\u001b[38;5;241m=\u001b[39mcollection, \n\u001b[1;32m      5\u001b[0m         documents\u001b[38;5;241m=\u001b[39m[snippet\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m snippet \u001b[38;5;129;01min\u001b[39;00m conversation_snippets\u001b[38;5;241m.\u001b[39msnippets], \n\u001b[1;32m      6\u001b[0m         ids\u001b[38;5;241m=\u001b[39m[snippet\u001b[38;5;241m.\u001b[39mid \u001b[38;5;28;01mfor\u001b[39;00m snippet \u001b[38;5;129;01min\u001b[39;00m conversation_snippets\u001b[38;5;241m.\u001b[39msnippets],\n\u001b[1;32m      7\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_of_event\u001b[39m\u001b[38;5;124m\"\u001b[39m: snippet\u001b[38;5;241m.\u001b[39mdate_of_event} \u001b[38;5;28;01mif\u001b[39;00m snippet\u001b[38;5;241m.\u001b[39mdate_of_event \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_of_event\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;28;01mfor\u001b[39;00m snippet \u001b[38;5;129;01min\u001b[39;00m conversation_snippets\u001b[38;5;241m.\u001b[39msnippets]\n\u001b[1;32m      8\u001b[0m     )\n\u001b[0;32m---> 10\u001b[0m \u001b[43minsert_snippets_to_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconversation_snippets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_snippets\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[172], line 6\u001b[0m, in \u001b[0;36minsert_snippets_to_index\u001b[0;34m(collection, conversation_snippets)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minsert_snippets_to_index\u001b[39m(collection, conversation_snippets: ConversationSnippets):\n\u001b[1;32m      3\u001b[0m     insert_to_index(\n\u001b[1;32m      4\u001b[0m         collection\u001b[38;5;241m=\u001b[39mcollection, \n\u001b[1;32m      5\u001b[0m         documents\u001b[38;5;241m=\u001b[39m[snippet\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m snippet \u001b[38;5;129;01min\u001b[39;00m conversation_snippets\u001b[38;5;241m.\u001b[39msnippets], \n\u001b[0;32m----> 6\u001b[0m         ids\u001b[38;5;241m=\u001b[39m\u001b[43m[\u001b[49m\u001b[43msnippet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msnippet\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconversation_snippets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msnippets\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m      7\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_of_event\u001b[39m\u001b[38;5;124m\"\u001b[39m: snippet\u001b[38;5;241m.\u001b[39mdate_of_event} \u001b[38;5;28;01mif\u001b[39;00m snippet\u001b[38;5;241m.\u001b[39mdate_of_event \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_of_event\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;28;01mfor\u001b[39;00m snippet \u001b[38;5;129;01min\u001b[39;00m conversation_snippets\u001b[38;5;241m.\u001b[39msnippets]\n\u001b[1;32m      8\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[172], line 6\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minsert_snippets_to_index\u001b[39m(collection, conversation_snippets: ConversationSnippets):\n\u001b[1;32m      3\u001b[0m     insert_to_index(\n\u001b[1;32m      4\u001b[0m         collection\u001b[38;5;241m=\u001b[39mcollection, \n\u001b[1;32m      5\u001b[0m         documents\u001b[38;5;241m=\u001b[39m[snippet\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m snippet \u001b[38;5;129;01min\u001b[39;00m conversation_snippets\u001b[38;5;241m.\u001b[39msnippets], \n\u001b[0;32m----> 6\u001b[0m         ids\u001b[38;5;241m=\u001b[39m[\u001b[43msnippet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m snippet \u001b[38;5;129;01min\u001b[39;00m conversation_snippets\u001b[38;5;241m.\u001b[39msnippets],\n\u001b[1;32m      7\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_of_event\u001b[39m\u001b[38;5;124m\"\u001b[39m: snippet\u001b[38;5;241m.\u001b[39mdate_of_event} \u001b[38;5;28;01mif\u001b[39;00m snippet\u001b[38;5;241m.\u001b[39mdate_of_event \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_of_event\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;28;01mfor\u001b[39;00m snippet \u001b[38;5;129;01min\u001b[39;00m conversation_snippets\u001b[38;5;241m.\u001b[39msnippets]\n\u001b[1;32m      8\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dev/lib/python3.11/site-packages/pydantic/main.py:856\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Snippet' object has no attribute 'id'"
     ]
    }
   ],
   "source": [
    "# insert to index\n",
    "def insert_snippets_to_index(collection, conversation_snippets: ConversationSnippets):\n",
    "    insert_to_index(\n",
    "        collection=collection, \n",
    "        documents=[snippet.text for snippet in conversation_snippets.snippets], \n",
    "        ids=[snippet.id for snippet in conversation_snippets.snippets],\n",
    "        metadatas=[{\"date_of_event\": snippet.date_of_event} if snippet.date_of_event else {\"date_of_event\": \"\"} for snippet in conversation_snippets.snippets]\n",
    "    )\n",
    "        \n",
    "insert_snippets_to_index(collection=collection, conversation_snippets=test_snippets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f4bef6-98a8-42cb-bd80-0fd2b3fc7f70",
   "metadata": {},
   "source": [
    "## [to be done] Deduplicating/Updating snippets against content in index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766d3a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c46f5c9b-464e-4e8f-8086-9c82b8057f98'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22380a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['962f71ce-c1b5-4542-bd0b-a209e52ad1c3']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(uuid.uuid4()) for i in range(len(documents))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "bf844c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class TagSnippetsWithDbActions(BaseModel):\n",
    "    snippets_to_add: Optional[list[Snippet]] = Field(description=\"The snippets to add to the database. Do not need id for these, as their ids will be generated upon insertion into the databse.\", default=None)\n",
    "    snippets_to_update: Optional[list[Snippet]]  = Field(description=\"The snippets to update in the database\", default=None)\n",
    "    snippets_to_delete: Optional[list[Snippet]]  = Field(description=\"The snippets to delete from the database\", default=None)\n",
    "\n",
    "\n",
    "TAG_PROMPT = \"\"\"\\\n",
    "TASK\n",
    "You can imagine that you are maintaining a journal of the user's career journey. \n",
    "Your task is to decide which snippets to add, update and delete in order to maintain a coherent memory the user.\n",
    "You should return ids and texts of snippets to add to the database.\n",
    "You are allowed to modify the text to maintain a coherent memory, but ensure the ids remain the same.\n",
    "You will be shown latest conversation snippets and prior snippets that are related to the current conversation.\n",
    "You are careful to insert the latest snippets while updating/deleting prior related snippets in order to maintain a coherent memory of the user's career journey.\n",
    "\n",
    "Prior related snippets sare extracted from an existing database(journal), and should either be deleted or updated based on the latest conversation text snippets. Ensure that the ids match the ids of the snippets in the database.\n",
    "Latest conversation texts are from the latest conversation between the user and their career confidant and should either be ignored or added. There is NO NEED to add the ids for them.\n",
    "\n",
    "You are provided with snippets of the latest conversation between a user and their career confidant, and prior related snippets that are already in memory.\n",
    "\n",
    "**\n",
    "EXAMPLE_INPUT:\n",
    "{{\n",
    "    \"latest_conversation_snippet_texts from 2024-11-20\": [\n",
    "        \"User previously considred becoming a data scientist.\",\n",
    "        \"User is considering becoming a softare engineer.\",\n",
    "        \"User has tried the Data Science course, and it doesn't really interest them.\"\n",
    "        \"User got laid off from their job.\",\n",
    "    ]\n",
    "    \"prior_related_snippets_extracted_from_db\": [\n",
    "        {{\n",
    "            \"text\": \"User is considering becoming a data scientist.\",\n",
    "            \"id\": '644ab910-aac1-45c8-acc0-1eef35d9f4e3'\n",
    "        }},\n",
    "        {{\n",
    "            \"text\": \"User is interested in working with data and wants to leverage programming skills. User is also going to start taking a course in data science.\",\n",
    "            \"id\": '49fbf3e3-3e68-4b0d-9df1-747af9778e94'\n",
    "        }},\n",
    "        {{\n",
    "            \"text\": User just got laid off from their job, yesterday\",\n",
    "            \"date_of_event\": \"2024-11-18\"\n",
    "            \"id\": 'ce617a99-cc06-478c-9ddb-7f041572a139',\n",
    "        }},\n",
    "    ]\n",
    "}}\n",
    "\n",
    "EXAMPLE_OUTPUT:\n",
    "{{\n",
    "    \"snippets_to_add\": [\n",
    "        {{\n",
    "            \"text\": \"User is considering becoming a softare engineer.\",\n",
    "        }},\n",
    "    ],\n",
    "    \"snippets_to_update\": [\n",
    "        {{\n",
    "            \"text\": \"User has tried the Data Science course, and it doesn't really interest them.\",\n",
    "            \"id\": '49fbf3e3-3e68-4b0d-9df1-747af9778e94'\n",
    "        }}\n",
    "    ],\n",
    "    \"snippets_to_delete\": []\n",
    "}}\n",
    "\n",
    "**\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "{output_format}\n",
    "\n",
    "INPUT:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "def _format_input(conversation_snippets:ConversationSnippets, prior_related_snippets:list[Snippet])->str:\n",
    "    latest_conversation_snippet_texts = [snippet.text for snippet in conversation_snippets.snippets]\n",
    "    # prior_related_snippets_extracted_from_db = [{\"text\": snippet.text, \"id\": snippet.id, \"date_of_event\": snippet.date_of_event} for snippet in prior_related_snippets.snippets]\n",
    "    return str({\n",
    "        \"latest_conversation_snippet_texts\": latest_conversation_snippet_texts,\n",
    "        \"prior_related_snippets_extracted_from_db\": [obj.model_dump() for obj in prior_related_snippets]\n",
    "    })\n",
    "\n",
    "def _tag_db_action_to_snippet(conversation_snippets: ConversationSnippets, prior_related_snippets: list[Snippet], model: str) -> TagSnippetsWithDbActions:\n",
    "    prompt = TAG_PROMPT.format(\n",
    "        output_format=TagSnippetsWithDbActions.model_json_schema(),\n",
    "        input=_format_input(conversation_snippets, prior_related_snippets)\n",
    "    )\n",
    "    tag_snippets_with_db_actions: TagSnippetsWithDbActions = chat_completion_request(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_model=TagSnippetsWithDbActions\n",
    "    )\n",
    "    logger.info(f\"Successfully tagged snippets with db actions\")\n",
    "    return tag_snippets_with_db_actions\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f30fde6",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 15 (1125354561.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[92], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    test_snippets\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 15\n"
     ]
    }
   ],
   "source": [
    "tag_snippets_with_db_actions = _tag_db_action_to_snippet(\n",
    "    conversation_snippets=ConversationSnippets(\n",
    "        snippets=[Snippet(text=\"User wants to be a software_engineer.\", date_of_event=\"2024-11-20\")],\n",
    "    ),\n",
    "    prior_related_snippets=test_snippets.snippets,\n",
    "    model=\"o1-preview\",\n",
    ")\n",
    "\n",
    "def _retrieve_related_snippets(snippet: Snippet, n_results: int = 3) -> list[Snippet]:\n",
    "    query_result = query_index(\n",
    "        query_texts=[snippet.text],\n",
    "        n_results=n_results,\n",
    "    )\n",
    "    query_result = _process_related_snippets(query_result)\n",
    "    \n",
    "    return query_result\n",
    "\n",
    "def _process_related_snippets(query_result: QueryResult)->list[Snippet]:\n",
    "    related_snippets = []\n",
    "    for doc, id, metadata in enumerate(query_result.documents[0], query_result.ids[0], query_result.metadatas[0]):\n",
    "        if query_result.metadatas[0] is not None:\n",
    "            \n",
    "        related_snippets.append(Snippet(text=snippet, date_of_event=query_result.metadatas[0].get(\"date_of_event\")))\n",
    "    return related_snippets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2746cbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['607de118-cdbb-4c5b-9dce-0d0ee0742d4f',\n",
       "   'a35f24ec-3ee0-4476-927a-2da5b96966f9',\n",
       "   '2742d17e-96a6-4334-b78c-42c27f6bffae']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['User is considering a career change.',\n",
       "   'User is considering a career change.',\n",
       "   'User is considering a career change.']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[{'date_of_evebt': ''},\n",
       "   {'date_of_evebt': ''},\n",
       "   {'date_of_evebt': ''}]],\n",
       " 'distances': [[1.624813437461853, 1.6248500347137451, 1.6248500347137451]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.query(\n",
    "    query_texts=[\"doc10\"],\n",
    "    n_results=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e78e7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45aae51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97be1059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c254b21a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc196d3-f429-4ae1-9c3f-664aab0afd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from datetime import datetime\n",
    "\n",
    "class Snippet(BaseModel):\n",
    "    snippet: str\n",
    "    date_of_event: Optional[str] = Field(description=\"to be filled in if the snippet is an event\", default=None)\n",
    "\n",
    "class ConversationSnippets(BaseModel):\n",
    "    snippets: list[Snippet]\n",
    "\n",
    "extract_snippets_from_conversation_prompt = \"\"\"\\\n",
    "You are to extract snippets of a given conversation between a career confidante and a user, which the confidante should take node of. Think of it as the confidante jotting key points down during the conversation in their journal.\n",
    "Each snippet has to contain sufficient information to stand alone and be understood without the context of the entire conversation.\n",
    "\n",
    "**\n",
    "IMPORTANT: Only return the output in JSON format. The JSON structure should be a list of snippet objects, each with the fields:\n",
    "\t•\t\"snippet\" (str): The extracted snippet from the conversation.\n",
    "\t•\t\"date_of_event\" (string): The date of the event mentioned in the snippet. If the snippet is not about an event, this field should be null. Date shouuld be formatted as \"YYYY-MM-DD\".\n",
    "\n",
    "Example conversation that happend on 2024-02-01:\n",
    "User: I am a software engineer and I am considering a career change.\n",
    "Confidante: What are you considering?\n",
    "User: I am considering becoming a data scientist.\n",
    "Confidante: What is motivating you to make this change?\n",
    "User: I am interested in working with data and I want to leverage my programming skills. I am also going to start taking a course in data science.\n",
    "Confidante: That's awesome, when do you plan to start the course?\n",
    "User: I plan to start next month.\n",
    "Confidante: Great!\n",
    "\n",
    "Example JSON:\n",
    "{{\n",
    "    \"snippets\": [\n",
    "        {{\n",
    "            \"snippet\": \"User is considering becoming a data scientist.\",\n",
    "            \"date_of_event\": null\n",
    "        }},\n",
    "        {{\n",
    "            \"snippet\": \"User is interested in working with data and wants to leverage programming skills. User is also going to start taking a course in data science.\",\n",
    "            \"date_of_event\": null\n",
    "        }},\n",
    "        {{\n",
    "            \"snippet\": \"User plans to start data science course next month.\",\n",
    "            \"date_of_event\": \"2024-03-01\"\n",
    "        }}\n",
    "\n",
    "    ]\n",
    "}}\n",
    "===== END OF EXAMPLE ======\n",
    "\n",
    "The 'snippets' key must be a list of snippets.\n",
    "The result must be a list of objects with 'snippet' and 'date_of_event' keys.\n",
    "Ensure each snippet contains sufficient information to stand alone and be understood without the context of the entire conversation.\n",
    "**\n",
    "\n",
    "Conversation that happened on {date}:\n",
    "{conversation}\n",
    "\n",
    "JSON:\n",
    "\"\"\"\n",
    "\n",
    "def determine_snippets_to_add_or_delete():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc54838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_documents_from_index():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75c5f62-44d0-4dd5-83de-59a0833130ec",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed1c73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store(user_messages:list[str], assistant_messages:list[str]):\n",
    "    conversation_snippets = extract_snippets_from_conversation(\n",
    "        user_messages=user_messages,\n",
    "        assistant_messages=assistant_messages\n",
    "    )\n",
    "    # determine_snippets_to_add_or_delete()\n",
    "    # delete_documents_from_index()\n",
    "    insert_snippets_to_index(collection=collection, conversation_snippets=conversation_snippets)\n",
    "    logger.info(f\"There are now {collection.count()} documents in the index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3af23a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f4c54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-20 23:22:24.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mextract_snippets_from_conversation\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1mSuccessfully extracted 4 snippets from conversation\u001b[0m\n",
      "\u001b[32m2024-11-20 23:22:25.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minsert_to_index\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mSuccessfully inserted 4 documents\u001b[0m\n",
      "\u001b[32m2024-11-20 23:22:25.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mstore\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mThere are now 20 documents in the index\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "store(\n",
    "    user_messages=[\"I just got laid off from my job.\", \"I am considering a career change.\", \"First, I am thinking of starting a course in data science.\", \"tomorrow\"],\n",
    "    assistant_messages=[\"What are you considering?\", \"What are your interests?\", \"When do you plan to start the course?\", \"That's great!\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652929dd-cbc8-4230-ac35-0d035696c4a9",
   "metadata": {},
   "source": [
    "# /Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1264c05e-808d-4c7b-9c8d-22fdb88651e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_DISTANCE=1.3\n",
    "K=10\n",
    "\n",
    "def _build_context(query_result: QueryResult, min_distance:float)->str:\n",
    "    documents = query_result.documents[0]\n",
    "    distances = query_result.distances[0]\n",
    "    context = [\"Here are some notes from previous conversations between you and the user that might be relevant to you. Note that this snippets are from conversations that happened in the past.\"]\n",
    "    context_num = 1\n",
    "    seen_contexts = set() # to handle exact duplicates that could inadvertedly be in the index\n",
    "    for document, distance in zip(documents, distances):\n",
    "        if distance < min_distance and document not in seen_contexts:\n",
    "            context.append(f\"{context_num}: {document}\")\n",
    "            context_num += 1\n",
    "            seen_contexts.add(document)\n",
    "    return \"\\n\".join(context)\n",
    "\n",
    "\n",
    "def retrieve(content_to_retrieve:str, min_distance:float=MIN_DISTANCE, k:int=K):\n",
    "    query_result = query_index(\n",
    "        query_texts=[content_to_retrieve],\n",
    "        n_results=k\n",
    "    )\n",
    "    return _build_context(query_result, min_distance)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77db495-2404-479d-bcd4-a8a09e8d18bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some notes from previous conversations between you and the user that might be relevant to you. Note that this snippets are from conversations that happened in the past.\n",
      "1: User is thinking of starting a course in data science.\n",
      "2: User plans to start the data science course tomorrow.\n",
      "3: User is considering a career change.\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "retrieval_result = retrieve(\"when is the user going to start a course?\")\n",
    "print(retrieval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b63e730-6b32-4343-9159-ba0e9036bee7",
   "metadata": {},
   "source": [
    "# /Recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447eddc4-4281-461e-a7e2-25dea725cb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recap():\n",
    "    return current_knowledge.knowledge\n",
    "\n",
    "UPDATE_KNOWLEDGE_PROMPT = \"\"\"\\\n",
    "You are a career confidante. Given a conversation that just happened between you and the user, and your current knowledge of the user, update your knowledge of the user.\n",
    "In your updated knowledge, you should include useful information for future interactions with the user.\n",
    "The conversation just happened, so you should integrate the new information from the conversation into your updated knowledge. \n",
    "\n",
    "Return only the updated knowledge in JSON format.\n",
    "\n",
    "The conversation is as follows:\n",
    "{conversation}\n",
    "\n",
    "Your current knowledge of the user is as follows:\n",
    "{knowledge}\n",
    "\n",
    "Response Format:\n",
    "{{\n",
    "    \"knowledge\": \"Updated knowledge of the user.\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "def update_knowledge(user_messages:list[str], assistant_messages:list[str], current_knowledge: CurrentKnowledge):\n",
    "    conversation = _construct_conversation(user_messages, assistant_messages)\n",
    "    prompt = UPDATE_KNOWLEDGE_PROMPT.format(conversation=conversation, knowledge=current_knowledge)\n",
    "    current_knowledge: CurrentKnowledge = chat_completion_request(\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_model=CurrentKnowledge\n",
    "    )\n",
    "    return current_knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd46ab-4644-4647-88bb-ded11e5e962e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knowledge='The user has recently been laid off from their job and is considering a career change. They are interested in data science and plan to start a course in this field tomorrow.'\n",
      "knowledge='The user has found a new job. They were recently laid off and were considering a career change, with an interest in data science. They planned to start a course in data science, but it is unclear if they have started or completed it. Future interactions should explore their new job role, satisfaction with the position, and whether they are still pursuing data science education or career change.'\n"
     ]
    }
   ],
   "source": [
    "current_knowledge = update_knowledge(\n",
    "    user_messages=[\"I just got laid off from my job.\", \"I am considering a career change.\", \"First, I am thinking of starting a course in data science.\", \"tomorrow\"],\n",
    "    assistant_messages=[\"What are you considering?\", \"What are your interests?\", \"When do you plan to start the course?\", \"That's great!\"],\n",
    "    current_knowledge=current_knowledge\n",
    ")\n",
    "print(current_knowledge)\n",
    "\n",
    "current_knowledge = update_knowledge(\n",
    "    user_messages=[\"I have found a job.\"],\n",
    "    assistant_messages=[\"That's great!\"],\n",
    "    current_knowledge=current_knowledge\n",
    ")\n",
    "print(current_knowledge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b45aaf2-fe86-43a7-bc2a-09d7cd0b8c5e",
   "metadata": {},
   "source": [
    "- Recap function\n",
    "- Prompt for context after recap/ retrieve\n",
    "- Prompt for context after receive has to include sorting on memories.\n",
    "- Need to include time of insertion?\n",
    "- Managing memory\n",
    "\n",
    "\n",
    "/retrieve\n",
    "- has to include date of event if available\n",
    "- [optional] probably needs to include a sorted order of ingestion time?\n",
    "\n",
    "/store \n",
    "- needs a way to modify memories. The idea is probably to provide a list of IDs and similar documents. Then ask it what we need to combine/update. \n",
    "- returns 2 fields (to_add, to_delete). They are lists of DocumentNode objects. (thinking that update can be replaced by add and delete functions.)\n",
    "- need to find a nice way to prompt \n",
    "\n",
    "\n",
    "[Optional]\n",
    "- Actively pushing events.\n",
    "- conversation chaining\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
