{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce2dcf1d-32b0-44f0-9030-cafc1fa17934",
   "metadata": {},
   "source": [
    "Goals:\n",
    "This notebook attempts to set up a POC for \"Infinite Memory\"\n",
    "1. Store\n",
    "2. Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "31cc2ac8-5e30-4572-ad81-a3378195b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import display\n",
    "from loguru import logger\n",
    "from openai import OpenAI\n",
    "from getpass import getpass\n",
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16830702-78af-4883-971d-fccce2c76144",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c66cab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = getpass(\"enter_openai_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0299cbb-e1ff-4804-a1bc-36073f9118b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "from typing import Type, Union, Any\n",
    "from llama_index.core.output_parsers.utils import parse_json_markdown\n",
    "import json\n",
    "\n",
    "openai_client = OpenAI(\n",
    "            api_key=openai_api_key,  \n",
    "        )\n",
    "\n",
    "def make_request(model: str, messages: list[dict[str, str]]) -> str:\n",
    "    start_time = time.time()\n",
    "    if model == \"gpt-4o\":\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0,\n",
    "        )\n",
    "    elif model == \"o1-preview\":\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid model: {model}\")\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "@retry(\n",
    "    stop=stop_after_attempt(3),\n",
    "    wait=wait_fixed(2),\n",
    ")\n",
    "def chat_completion_request(\n",
    "    messages: list[dict[str, str]],\n",
    "    model: str = \"gpt-4o\",\n",
    "    response_model: Type[BaseModel] = None,\n",
    ") -> Union[str, dict[str, Any]]:\n",
    "    try:\n",
    "        content = make_request(model, messages)\n",
    "        if response_model is not None:\n",
    "            parsed_content = parse_json_markdown(content)\n",
    "            try:\n",
    "                return response_model(**parsed_content)\n",
    "            except TypeError as e:\n",
    "                error_message = {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"JSON decoding error: {e}. Please adhere to the json response format that obeys the following schema: {response_model.model_json_schema()}\",\n",
    "                }\n",
    "                messages.append(error_message)\n",
    "                logger.error(\n",
    "                    f\"TypeError in response_model parsing: {e}. Content: {parsed_content}\"\n",
    "                )\n",
    "                raise\n",
    "        else:\n",
    "            return content\n",
    "    except json.JSONDecodeError as e:\n",
    "        error_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"JSON decoding error: {e}. Please adhere to the json response format that obeys the following schema: {response_model.model_json_schema()}\",\n",
    "        }\n",
    "        messages.append(error_message)\n",
    "        logger.error(f\"JSON decoding error: {e}. Content: {content}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error while making chat completion request: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d650a3c-0abe-4184-8ed2-4e21fbc837ea",
   "metadata": {},
   "source": [
    "# Intialize Memory - DB and Chat Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8814cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "class CurrentKnowledge(BaseModel):\n",
    "    knowledge: Optional[str] = Field(description=\"The current knowledge of the user\", default=None)\n",
    "\n",
    "current_knowledge = CurrentKnowledge(knowledge='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "18d9996b-7900-482c-9b7f-d07b8546f847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.EphemeralClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7008032d-d6b8-4079-ab49-7fef5ce0194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "\n",
    "class CustomOpenAIEmbeddingFunction(EmbeddingFunction):\n",
    "    def __call__(self, input: list[str]) -> Embeddings:\n",
    "        input = [text.replace(\"\\n\", \" \") for text in input]\n",
    "        emb_resp = openai_client.embeddings.create(input=input, model='text-embedding-3-small').data\n",
    "        return [emb.embedding for emb in emb_resp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "947de1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chroma_client.delete_collection(\"user_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "25ac1b1e-3ea7-44cf-bc88-64cdc9f2be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.get_or_create_collection(name=\"user_history\", embedding_function=CustomOpenAIEmbeddingFunction()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2692de8e-855f-4249-b771-28de4dda34d8",
   "metadata": {},
   "source": [
    "# Create functions to add, delete and query DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d627b1eb-4e17-4a9e-9e17-8111a9a72cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Delete of nonexisting embedding ID: ce617a99-cc06-478c-9ddb-7f041572a139\n",
      "Delete of nonexisting embedding ID: b5c1f87b-3e66-4dd0-8bcf-02b6d523a74c\n",
      "Delete of nonexisting embedding ID: ce617a99-cc06-478c-9ddb-7f041572a139\n",
      "Delete of nonexisting embedding ID: b5c1f87b-3e66-4dd0-8bcf-02b6d523a74c\n"
     ]
    }
   ],
   "source": [
    "# deleting\n",
    "def delete_from_index(collection, ids):\n",
    "    collection.delete(\n",
    "        ids=ids\n",
    "    )\n",
    "delete_from_index(collection=collection,ids=['ce617a99-cc06-478c-9ddb-7f041572a139',\n",
    "  'b5c1f87b-3e66-4dd0-8bcf-02b6d523a74c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af945109-33c1-4713-b88d-fdbd9612633e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-22 12:32:53.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minsert_to_index\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mSuccessfully inserted 1 documents\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "# inserting\n",
    "def insert_to_index(collection, documents:list[str], metadatas=None):\n",
    "    collection.add(\n",
    "        documents=documents,\n",
    "        metadatas=metadatas,\n",
    "        ids=[str(uuid.uuid4()) for i in range(len(documents))],\n",
    "    )\n",
    "    logger.info(f\"Successfully inserted {len(documents)} documents\")\n",
    "\n",
    "insert_to_index(collection=collection, documents=['user wants to be a software engineer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1b5b668c-e12b-4b39-b144-2d72062d093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryResult(BaseModel):\n",
    "    ids: list[list[str]]\n",
    "    documents: list[list[str]]\n",
    "    distances: list[list[float]]\n",
    "    metadatas: list[list[Optional[dict[str, str]]]]\n",
    "\n",
    "# querying https://docs.trychroma.com/guides#filtering-by-metadata\n",
    "def query_index(query_texts, n_results=1, where=None, where_document=None):\n",
    "    n_results = min(n_results, collection.count())\n",
    "    query_result = collection.query(\n",
    "        query_texts=query_texts,\n",
    "        n_results=n_results,\n",
    "        where=where,\n",
    "        where_document=where_document,\n",
    "    )\n",
    "    return QueryResult(**query_result)\n",
    "    \n",
    "query_result = query_index(\n",
    "    query_texts=[\"female\", \"male\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "f877fcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_index(ids, documents, metadatas=None):\n",
    "    collection.update(\n",
    "        ids=ids,\n",
    "        metadatas=metadatas,\n",
    "        documents=documents,\n",
    "    )\n",
    "    logger.info(f\"Successfully updated {len(ids)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc02dd1-cf8e-4a31-b93a-0455890f8428",
   "metadata": {},
   "source": [
    "# /Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37a6205",
   "metadata": {},
   "source": [
    "## extract_snippets_from_conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b35212f-30f0-4046-9bd5-1ab77833e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class Snippet(BaseModel):\n",
    "    text: str\n",
    "    date_of_event: Optional[str] = Field(description=\"to be filled in if the snippet is an event\", default=None) # TODO not sure what to do with this info for now\n",
    "    id: Optional[str] = Field(description=\"id of the snippet\", default=None)\n",
    "\n",
    "class ConversationSnippets(BaseModel):\n",
    "    snippets: list[Snippet]\n",
    "\n",
    "extract_snippets_from_conversation_prompt = \"\"\"\\\n",
    "You are to extract snippets of a given conversation between a career confidante and a user, which the confidante should take node of. Think of it as the confidante jotting key points down during the conversation in their journal.\n",
    "Each snippet has to contain sufficient information to stand alone and be understood without the context of the entire conversation.\n",
    "\n",
    "**\n",
    "IMPORTANT: Only return the output in JSON format. The JSON structure should be a list of snippet objects, each with the fields:\n",
    "\t•\t\"text\" (str): The extracted text snippet from the conversation.\n",
    "\t•\t\"date_of_event\" (string): The date of the event mentioned in the snippet. If the snippet is not about an event, this field should be null. Date shouuld be formatted as \"YYYY-MM-DD\".\n",
    "\n",
    "Example conversation that happend on 2024-02-01:\n",
    "User: I am a software engineer and I am considering a career change.\n",
    "Confidante: What are you considering?\n",
    "User: I am considering becoming a data scientist.\n",
    "Confidante: What is motivating you to make this change?\n",
    "User: I am interested in working with data and I want to leverage my programming skills. I am also going to start taking a course in data science.\n",
    "Confidante: That's awesome, when do you plan to start the course?\n",
    "User: I plan to start next month.\n",
    "Confidante: Great!\n",
    "\n",
    "Example JSON:\n",
    "{{\n",
    "    \"snippets\": [\n",
    "        {{\n",
    "            \"text\": \"User is considering becoming a data scientist.\",\n",
    "            \"date_of_event\": null\n",
    "        }},\n",
    "        {{\n",
    "            \"text\": \"User is interested in working with data and wants to leverage programming skills. User is also going to start taking a course in data science.\",\n",
    "            \"date_of_event\": null\n",
    "        }},\n",
    "        {{\n",
    "            \"text\": \"User plans to start data science course next month.\",\n",
    "            \"date_of_event\": \"2024-03-01\"\n",
    "        }}\n",
    "\n",
    "    ]\n",
    "}}\n",
    "===== END OF EXAMPLE ======\n",
    "\n",
    "The 'snippets' key must be a list of snippets.\n",
    "The result must be a list of objects with 'text' and 'date_of_event' keys.\n",
    "Ensure each snippet contains sufficient information to stand alone and be understood without the context of the entire conversation.\n",
    "**\n",
    "\n",
    "Conversation that happened on {date}:\n",
    "{conversation}\n",
    "\n",
    "JSON:\n",
    "\"\"\"\n",
    "\n",
    "def _get_date_today():\n",
    "    return datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def _construct_conversation(user_messages:list[str], assistant_messages:list[str])->str:\n",
    "    conversation = []\n",
    "    for user_message, assistant_message in zip(user_messages, assistant_messages):\n",
    "        conversation.append(f\"User: {user_message}\")\n",
    "        conversation.append(f\"Confidante: {assistant_message}\")\n",
    "    return \"\\n\".join(conversation)\n",
    "\n",
    "def extract_snippets_from_conversation(user_messages:list[str], assistant_messages:list[str]):\n",
    "    conversation = _construct_conversation(user_messages, assistant_messages)\n",
    "    prompt = extract_snippets_from_conversation_prompt.format(date=_get_date_today(), conversation=conversation)\n",
    "    conversation_snippets: ConversationSnippets = chat_completion_request(\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_model=ConversationSnippets\n",
    "    )\n",
    "    logger.info(f\"Successfully extracted {len(conversation_snippets.snippets)} snippets from conversation\")\n",
    "    return conversation_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264acf22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationSnippets(snippets=[Snippet(text='User just got laid off from their job.', date_of_event=None), Snippet(text='User is considering a career change.', date_of_event=None), Snippet(text='User is thinking of starting a course in data science.', date_of_event=None), Snippet(text='User plans to start the data science course tomorrow.', date_of_event='2024-11-21')])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test case\n",
    "test_snippets = extract_snippets_from_conversation(\n",
    "    user_messages=[\"I just got laid off from my job.\", \"I am considering a career change.\", \"First, I am thinking of starting a course in data science.\", \"tomorrow\"],\n",
    "    assistant_messages=[\"What are you considering?\", \"What are your interests?\", \"When do you plan to start the course?\", \"That's great!\"]\n",
    ")\n",
    "test_snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f4bef6-98a8-42cb-bd80-0fd2b3fc7f70",
   "metadata": {},
   "source": [
    "## [to be done] Deduplicating/Updating snippets against content in index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "bf844c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class TaggedSnippetsWithDbActions(BaseModel):\n",
    "    snippets_to_add: Optional[list[Snippet]] = Field(description=\"The snippets to add to the database. Do not need id for these, as their ids will be generated upon insertion into the databse.\", default=None)\n",
    "    snippets_to_update: Optional[list[Snippet]]  = Field(description=\"The snippets to update in the database\", default=None)\n",
    "    snippets_to_delete: Optional[list[Snippet]]  = Field(description=\"The snippets to delete from the database\", default=None)\n",
    "\n",
    "\n",
    "TAG_PROMPT = \"\"\"\\\n",
    "TASK\n",
    "You can imagine that you are maintaining a journal of the user's career journey. \n",
    "Your task is to decide which snippets to add, update and delete in order to maintain a coherent memory the user.\n",
    "You should return ids and texts of snippets to add to the database.\n",
    "You are allowed to modify the text to maintain a coherent memory, but ensure the ids remain the same.\n",
    "You will be shown latest conversation snippets and prior snippets that are related to the current conversation.\n",
    "You are careful to insert the latest snippets while updating/deleting prior related snippets in order to maintain a coherent memory of the user's career journey.\n",
    "\n",
    "Prior related snippets sare extracted from an existing database(journal), and should either be deleted or updated based on the latest conversation text snippets. Ensure that the ids match the ids of the snippets in the database.\n",
    "Latest conversation texts are from the latest conversation between the user and their career confidant and should either be ignored or added. There is NO NEED to add the ids for them.\n",
    "\n",
    "You are provided with snippets of the latest conversation between a user and their career confidant, and prior related snippets that are already in memory.\n",
    "\n",
    "**\n",
    "EXAMPLE_INPUT:\n",
    "{{\n",
    "    \"latest_conversation_snippet_texts from 2024-11-20\": [\n",
    "        \"User previously considred becoming a data scientist.\",\n",
    "        \"User is considering becoming a softare engineer.\",\n",
    "        \"User has tried the Data Science course, and it doesn't really interest them.\"\n",
    "        \"User got laid off from their job.\",\n",
    "    ]\n",
    "    \"prior_related_snippets_extracted_from_db\": [\n",
    "        {{\n",
    "            \"text\": \"User is considering becoming a data scientist.\",\n",
    "            \"id\": '644ab910-aac1-45c8-acc0-1eef35d9f4e3'\n",
    "        }},\n",
    "        {{\n",
    "            \"text\": \"User is interested in working with data and wants to leverage programming skills. User is also going to start taking a course in data science.\",\n",
    "            \"id\": '49fbf3e3-3e68-4b0d-9df1-747af9778e94'\n",
    "        }},\n",
    "        {{\n",
    "            \"text\": User just got laid off from their job, yesterday\",\n",
    "            \"date_of_event\": \"2024-11-18\"\n",
    "            \"id\": 'ce617a99-cc06-478c-9ddb-7f041572a139',\n",
    "        }},\n",
    "    ]\n",
    "}}\n",
    "\n",
    "EXAMPLE_OUTPUT:\n",
    "{{\n",
    "    \"snippets_to_add\": [\n",
    "        {{\n",
    "            \"text\": \"User is considering becoming a softare engineer.\",\n",
    "        }},\n",
    "    ],\n",
    "    \"snippets_to_update\": [\n",
    "        {{\n",
    "            \"text\": \"User has tried the Data Science course, and it doesn't really interest them.\",\n",
    "            \"id\": '49fbf3e3-3e68-4b0d-9df1-747af9778e94'\n",
    "        }}\n",
    "    ],\n",
    "    \"snippets_to_delete\": []\n",
    "}}\n",
    "\n",
    "**\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "{output_format}\n",
    "\n",
    "INPUT:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "def _format_input(conversation_snippets:ConversationSnippets, prior_related_snippets:list[Snippet])->str:\n",
    "    print(conversation_snippets)\n",
    "    latest_conversation_snippet_texts = [snippet.text for snippet in conversation_snippets.snippets]\n",
    "    # prior_related_snippets_extracted_from_db = [{\"text\": snippet.text, \"id\": snippet.id, \"date_of_event\": snippet.date_of_event} for snippet in prior_related_snippets.snippets]\n",
    "    return str({\n",
    "        \"latest_conversation_snippet_texts\": latest_conversation_snippet_texts,\n",
    "        \"prior_related_snippets_extracted_from_db\": [obj.model_dump() for obj in prior_related_snippets]\n",
    "    })\n",
    "\n",
    "def _tag_db_action_to_snippet(conversation_snippets: ConversationSnippets, prior_related_snippets: list[Snippet], model: str) -> TaggedSnippetsWithDbActions:\n",
    "    prompt = TAG_PROMPT.format(\n",
    "        output_format=TaggedSnippetsWithDbActions.model_json_schema(),\n",
    "        input=_format_input(conversation_snippets, prior_related_snippets)\n",
    "    )\n",
    "    tag_snippets_with_db_actions: TaggedSnippetsWithDbActions = chat_completion_request(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_model=TaggedSnippetsWithDbActions\n",
    "    )\n",
    "    logger.info(f\"Successfully tagged snippets with db actions\")\n",
    "    return tag_snippets_with_db_actions\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "4f30fde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag_snippets_with_db_actions = _tag_db_action_to_snippet(\n",
    "#     conversation_snippets=ConversationSnippets(\n",
    "#         snippets=[Snippet(text=\"User wants to be a software_engineer.\", date_of_event=\"2024-11-20\")],\n",
    "#     ),\n",
    "#     prior_related_snippets=test_snippets.snippets,\n",
    "#     model=\"o1-preview\",\n",
    "# )\n",
    "\n",
    "def _retrieve_related_snippets(snippet: Snippet, n_results: int = 3) -> QueryResult:\n",
    "    print(snippet)\n",
    "    query_result = query_index(\n",
    "        query_texts=[snippet.text],\n",
    "        n_results=n_results,\n",
    "    )\n",
    "    return query_result\n",
    "\n",
    "def _process_related_snippets(query_result: QueryResult)->list[Snippet]:\n",
    "    related_snippets = []\n",
    "    for doc, id, metadata in zip(query_result.documents[0], query_result.ids[0], query_result.metadatas[0]):\n",
    "        if metadata is not None and metadata['date_of_event'] is not None:\n",
    "            related_snippets.append(Snippet(text=doc, date_of_event=metadata['date_of_event'], id=id))\n",
    "        else:\n",
    "            related_snippets.append(Snippet(text=doc, date_of_event='', id=id,))\n",
    "    return related_snippets\n",
    "\n",
    "def _clean_tagged_snippets_with_db_actions(prev_ids, tagged_snippets_with_db_actions: TaggedSnippetsWithDbActions)->tuple[list[Snippet], list[Snippet], list[Snippet]]:\n",
    "    snippets_to_add = tagged_snippets_with_db_actions.snippets_to_add\n",
    "    snippets_to_update = [snippet for snippet in tagged_snippets_with_db_actions.snippets_to_update if snippet.id in prev_ids]\n",
    "    snippets_to_delete = [snippet for snippet in tagged_snippets_with_db_actions.snippets_to_delete if snippet.id in prev_ids]\n",
    "    return snippets_to_add, snippets_to_update, snippets_to_delete\n",
    "\n",
    "\n",
    "def _execute_db_actions(collection, snippets_to_add:list[Snippet], snippets_to_update:list[Snippet], snippets_to_delete:list[Snippet]):\n",
    "    if snippets_to_add:\n",
    "        insert_to_index(\n",
    "            collection=collection, \n",
    "            documents=[snippet.text for snippet in snippets_to_add],\n",
    "            metadatas=[{\"date_of_event\": snippet.date_of_event} if snippet.date_of_event else {\"date_of_event\": \"\"} for snippet in snippets_to_add]\n",
    "        )\n",
    "    if snippets_to_update:\n",
    "        update_index(\n",
    "            ids=[snippet.id for snippet in snippets_to_update],\n",
    "            documents=[snippet.text for snippet in snippets_to_update],\n",
    "        )\n",
    "    if snippets_to_delete:\n",
    "        delete_from_index(collection=collection, ids=[snippet.id for snippet in snippets_to_delete])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "9e78e7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='User only wants to be an astronaut now.' date_of_event='2024-11-20' id=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-22 12:49:34.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmaintain_index\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mSuccessfully retrieved related snippets. [Snippet(text='user wants to be a software engineer', date_of_event='', id='fe414d8a-9d13-447b-b761-eb6e108af64e')]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snippets=[Snippet(text='User only wants to be an astronaut now.', date_of_event='2024-11-20', id=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-22 12:49:54.017\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_tag_db_action_to_snippet\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1mSuccessfully tagged snippets with db actions\u001b[0m\n",
      "\u001b[32m2024-11-22 12:49:54.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmaintain_index\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mSuccessfully tagged snippets with db actions. snippets_to_add=[Snippet(text='User only wants to be an astronaut now.', date_of_event=None, id=None)] snippets_to_update=[Snippet(text='User previously wanted to be a software engineer but now aims to become an astronaut.', date_of_event=None, id='fe414d8a-9d13-447b-b761-eb6e108af64e')] snippets_to_delete=[]\u001b[0m\n",
      "\u001b[32m2024-11-22 12:49:54.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmaintain_index\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mSuccessfully cleaned tagged snippets with db actions, [Snippet(text='User only wants to be an astronaut now.', date_of_event=None, id=None)], [Snippet(text='User previously wanted to be a software engineer but now aims to become an astronaut.', date_of_event=None, id='fe414d8a-9d13-447b-b761-eb6e108af64e')], []\u001b[0m\n",
      "\u001b[32m2024-11-22 12:49:54.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minsert_to_index\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mSuccessfully inserted 1 documents\u001b[0m\n",
      "\u001b[32m2024-11-22 12:49:54.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mupdate_index\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mSuccessfully updated 1 documents\u001b[0m\n",
      "\u001b[32m2024-11-22 12:49:54.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmaintain_index\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mSuccessfully executed db actions\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[233], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m     _execute_db_actions(collection, snippets_to_add, snippets_to_update, snippets_to_delete)\n\u001b[1;32m     23\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully executed db actions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m snippets_to_add, snippets_to_update, snippets_to_delete \u001b[38;5;241m=\u001b[39m maintain_index(\n\u001b[1;32m     27\u001b[0m     collection\u001b[38;5;241m=\u001b[39mcollection, \n\u001b[1;32m     28\u001b[0m     conversation_snippets\u001b[38;5;241m=\u001b[39mConversationSnippets(\n\u001b[1;32m     29\u001b[0m         snippets\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     30\u001b[0m             Snippet(text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser only wants to be an astronaut now.\u001b[39m\u001b[38;5;124m\"\u001b[39m, date_of_event\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2024-11-20\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m         ]\n\u001b[1;32m     32\u001b[0m     )\n\u001b[1;32m     33\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "def maintain_index(collection, conversation_snippets: ConversationSnippets):\n",
    "    all_related_snippets = []\n",
    "    seen = set()\n",
    "    for snippet in conversation_snippets.snippets:\n",
    "       query_result =  _retrieve_related_snippets(snippet)\n",
    "       related_snippets = _process_related_snippets(query_result)\n",
    "       for snippet in related_snippets:\n",
    "           if snippet.id not in seen:\n",
    "               all_related_snippets.append(snippet)\n",
    "               seen.add(snippet.id)\n",
    "    logger.info(f\"Successfully retrieved related snippets. {all_related_snippets}\")\n",
    "    prev_ids = set([snippet.id for snippet in all_related_snippets])\n",
    "    tag_snippets_with_db_actions = _tag_db_action_to_snippet(\n",
    "        conversation_snippets=conversation_snippets,\n",
    "        prior_related_snippets=all_related_snippets,\n",
    "        model=\"o1-preview\",\n",
    "    )\n",
    "    logger.info(f\"Successfully tagged snippets with db actions. {tag_snippets_with_db_actions}\")\n",
    "    snippets_to_add, snippets_to_update, snippets_to_delete = _clean_tagged_snippets_with_db_actions(prev_ids, tag_snippets_with_db_actions)\n",
    "    logger.info(f\"Successfully cleaned tagged snippets with db actions, {snippets_to_add}, {snippets_to_update}, {snippets_to_delete}\")\n",
    "    # return snippets_to_add, snippets_to_update, snippets_to_delete\n",
    "    _execute_db_actions(collection, snippets_to_add, snippets_to_update, snippets_to_delete)\n",
    "    logger.info(f\"Successfully executed db actions\")\n",
    "\n",
    "        \n",
    "maintain_index(\n",
    "    collection=collection, \n",
    "    conversation_snippets=ConversationSnippets(\n",
    "        snippets=[\n",
    "            Snippet(text=\"User only wants to be an astronaut now.\", date_of_event=\"2024-11-20\")\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "20145e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Snippet(text='User only wants to be an astronaut now.', date_of_event=None, id=None)]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippets_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f45aae51",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected metadata value to be a str, int, float or bool, got None which is a NoneType in add.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/miniconda3/envs/dev/lib/python3.11/site-packages/chromadb/api/models/CollectionCommon.py:90\u001b[0m, in \u001b[0;36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dev/lib/python3.11/site-packages/chromadb/api/models/CollectionCommon.py:207\u001b[0m, in \u001b[0;36mCollectionCommon._validate_and_prepare_add_request\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m \u001b[43mvalidate_insert_record_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_records\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m validate_record_set_contains_any(record_set\u001b[38;5;241m=\u001b[39madd_records, contains_any\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dev/lib/python3.11/site-packages/chromadb/api/types.py:224\u001b[0m, in \u001b[0;36mvalidate_insert_record_set\u001b[0;34m(record_set)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m record_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadatas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 224\u001b[0m     \u001b[43mvalidate_metadatas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadatas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dev/lib/python3.11/site-packages/chromadb/api/types.py:586\u001b[0m, in \u001b[0;36mvalidate_metadatas\u001b[0;34m(metadatas)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metadata \u001b[38;5;129;01min\u001b[39;00m metadatas:\n\u001b[0;32m--> 586\u001b[0m     \u001b[43mvalidate_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metadatas\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dev/lib/python3.11/site-packages/chromadb/api/types.py:552\u001b[0m, in \u001b[0;36mvalidate_metadata\u001b[0;34m(metadata)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)):\n\u001b[0;32m--> 552\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    553\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected metadata value to be a str, int, float or bool, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m which is a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    554\u001b[0m         )\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metadata\n",
      "\u001b[0;31mValueError\u001b[0m: Expected metadata value to be a str, int, float or bool, got None which is a NoneType",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[230], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m_execute_db_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnippets_to_add\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnippets_to_update\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnippets_to_delete\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[221], line 35\u001b[0m, in \u001b[0;36m_execute_db_actions\u001b[0;34m(collection, snippets_to_add, snippets_to_update, snippets_to_delete)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute_db_actions\u001b[39m(collection, snippets_to_add:\u001b[38;5;28mlist\u001b[39m[Snippet], snippets_to_update:\u001b[38;5;28mlist\u001b[39m[Snippet], snippets_to_delete:\u001b[38;5;28mlist\u001b[39m[Snippet]):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m snippets_to_add:\n\u001b[0;32m---> 35\u001b[0m         \u001b[43minsert_to_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msnippet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msnippet\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msnippets_to_add\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate_of_event\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msnippet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdate_of_event\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msnippet\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msnippets_to_add\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m snippets_to_update:\n\u001b[1;32m     41\u001b[0m         update_index(\n\u001b[1;32m     42\u001b[0m             ids\u001b[38;5;241m=\u001b[39m[snippet\u001b[38;5;241m.\u001b[39mid \u001b[38;5;28;01mfor\u001b[39;00m snippet \u001b[38;5;129;01min\u001b[39;00m snippets_to_update],\n\u001b[1;32m     43\u001b[0m             documents\u001b[38;5;241m=\u001b[39m[snippet\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m snippet \u001b[38;5;129;01min\u001b[39;00m snippets_to_update],\n\u001b[1;32m     44\u001b[0m         )\n",
      "Cell \u001b[0;32mIn[202], line 4\u001b[0m, in \u001b[0;36minsert_to_index\u001b[0;34m(collection, documents, metadatas)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minsert_to_index\u001b[39m(collection, documents:\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m], metadatas\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muuid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muuid4\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully inserted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(documents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m documents\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dev/lib/python3.11/site-packages/chromadb/api/models/Collection.py:81\u001b[0m, in \u001b[0;36mCollection.add\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd\u001b[39m(\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     48\u001b[0m     ids: OneOrMany[ID],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     uris: Optional[OneOrMany[URI]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     59\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Add embeddings to the data store.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m        ids: The ids of the embeddings you wish to add\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m \n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m     add_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_and_prepare_add_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43muris\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_add(\n\u001b[1;32m     91\u001b[0m         collection_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m     92\u001b[0m         ids\u001b[38;5;241m=\u001b[39madd_request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m         database\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatabase,\n\u001b[1;32m     99\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dev/lib/python3.11/site-packages/chromadb/api/models/CollectionCommon.py:93\u001b[0m, in \u001b[0;36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     92\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(msg)\u001b[38;5;241m.\u001b[39mwith_traceback(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dev/lib/python3.11/site-packages/chromadb/api/models/CollectionCommon.py:90\u001b[0m, in \u001b[0;36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     92\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dev/lib/python3.11/site-packages/chromadb/api/models/CollectionCommon.py:207\u001b[0m, in \u001b[0;36mCollectionCommon._validate_and_prepare_add_request\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[1;32m    197\u001b[0m add_records \u001b[38;5;241m=\u001b[39m normalize_insert_record_set(\n\u001b[1;32m    198\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m    199\u001b[0m     embeddings\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    203\u001b[0m     uris\u001b[38;5;241m=\u001b[39muris,\n\u001b[1;32m    204\u001b[0m )\n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m \u001b[43mvalidate_insert_record_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_records\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m validate_record_set_contains_any(record_set\u001b[38;5;241m=\u001b[39madd_records, contains_any\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# Prepare\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dev/lib/python3.11/site-packages/chromadb/api/types.py:224\u001b[0m, in \u001b[0;36mvalidate_insert_record_set\u001b[0;34m(record_set)\u001b[0m\n\u001b[1;32m    222\u001b[0m validate_ids(record_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m record_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadatas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 224\u001b[0m     \u001b[43mvalidate_metadatas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadatas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dev/lib/python3.11/site-packages/chromadb/api/types.py:586\u001b[0m, in \u001b[0;36mvalidate_metadatas\u001b[0;34m(metadatas)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected metadatas to be a list, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetadatas\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metadata \u001b[38;5;129;01min\u001b[39;00m metadatas:\n\u001b[0;32m--> 586\u001b[0m     \u001b[43mvalidate_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metadatas\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dev/lib/python3.11/site-packages/chromadb/api/types.py:552\u001b[0m, in \u001b[0;36mvalidate_metadata\u001b[0;34m(metadata)\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;66;03m# isinstance(True, int) evaluates to True, so we need to check for bools separately\u001b[39;00m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)):\n\u001b[0;32m--> 552\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    553\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected metadata value to be a str, int, float or bool, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m which is a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    554\u001b[0m         )\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metadata\n",
      "\u001b[0;31mValueError\u001b[0m: Expected metadata value to be a str, int, float or bool, got None which is a NoneType in add."
     ]
    }
   ],
   "source": [
    "_execute_db_actions(collection, snippets_to_add, snippets_to_update, snippets_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c254b21a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc196d3-f429-4ae1-9c3f-664aab0afd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from datetime import datetime\n",
    "\n",
    "class Snippet(BaseModel):\n",
    "    snippet: str\n",
    "    date_of_event: Optional[str] = Field(description=\"to be filled in if the snippet is an event\", default=None)\n",
    "\n",
    "class ConversationSnippets(BaseModel):\n",
    "    snippets: list[Snippet]\n",
    "\n",
    "extract_snippets_from_conversation_prompt = \"\"\"\\\n",
    "You are to extract snippets of a given conversation between a career confidante and a user, which the confidante should take node of. Think of it as the confidante jotting key points down during the conversation in their journal.\n",
    "Each snippet has to contain sufficient information to stand alone and be understood without the context of the entire conversation.\n",
    "\n",
    "**\n",
    "IMPORTANT: Only return the output in JSON format. The JSON structure should be a list of snippet objects, each with the fields:\n",
    "\t•\t\"snippet\" (str): The extracted snippet from the conversation.\n",
    "\t•\t\"date_of_event\" (string): The date of the event mentioned in the snippet. If the snippet is not about an event, this field should be null. Date shouuld be formatted as \"YYYY-MM-DD\".\n",
    "\n",
    "Example conversation that happend on 2024-02-01:\n",
    "User: I am a software engineer and I am considering a career change.\n",
    "Confidante: What are you considering?\n",
    "User: I am considering becoming a data scientist.\n",
    "Confidante: What is motivating you to make this change?\n",
    "User: I am interested in working with data and I want to leverage my programming skills. I am also going to start taking a course in data science.\n",
    "Confidante: That's awesome, when do you plan to start the course?\n",
    "User: I plan to start next month.\n",
    "Confidante: Great!\n",
    "\n",
    "Example JSON:\n",
    "{{\n",
    "    \"snippets\": [\n",
    "        {{\n",
    "            \"snippet\": \"User is considering becoming a data scientist.\",\n",
    "            \"date_of_event\": null\n",
    "        }},\n",
    "        {{\n",
    "            \"snippet\": \"User is interested in working with data and wants to leverage programming skills. User is also going to start taking a course in data science.\",\n",
    "            \"date_of_event\": null\n",
    "        }},\n",
    "        {{\n",
    "            \"snippet\": \"User plans to start data science course next month.\",\n",
    "            \"date_of_event\": \"2024-03-01\"\n",
    "        }}\n",
    "\n",
    "    ]\n",
    "}}\n",
    "===== END OF EXAMPLE ======\n",
    "\n",
    "The 'snippets' key must be a list of snippets.\n",
    "The result must be a list of objects with 'snippet' and 'date_of_event' keys.\n",
    "Ensure each snippet contains sufficient information to stand alone and be understood without the context of the entire conversation.\n",
    "**\n",
    "\n",
    "Conversation that happened on {date}:\n",
    "{conversation}\n",
    "\n",
    "JSON:\n",
    "\"\"\"\n",
    "\n",
    "def determine_snippets_to_add_or_delete():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc54838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_documents_from_index():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75c5f62-44d0-4dd5-83de-59a0833130ec",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed1c73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store(user_messages:list[str], assistant_messages:list[str]):\n",
    "    conversation_snippets = extract_snippets_from_conversation(\n",
    "        user_messages=user_messages,\n",
    "        assistant_messages=assistant_messages\n",
    "    )\n",
    "    # determine_snippets_to_add_or_delete()\n",
    "    # delete_documents_from_index()\n",
    "    insert_snippets_to_index(collection=collection, conversation_snippets=conversation_snippets)\n",
    "    logger.info(f\"There are now {collection.count()} documents in the index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3af23a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f4c54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-20 23:22:24.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mextract_snippets_from_conversation\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1mSuccessfully extracted 4 snippets from conversation\u001b[0m\n",
      "\u001b[32m2024-11-20 23:22:25.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minsert_to_index\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mSuccessfully inserted 4 documents\u001b[0m\n",
      "\u001b[32m2024-11-20 23:22:25.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mstore\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mThere are now 20 documents in the index\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "store(\n",
    "    user_messages=[\"I just got laid off from my job.\", \"I am considering a career change.\", \"First, I am thinking of starting a course in data science.\", \"tomorrow\"],\n",
    "    assistant_messages=[\"What are you considering?\", \"What are your interests?\", \"When do you plan to start the course?\", \"That's great!\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652929dd-cbc8-4230-ac35-0d035696c4a9",
   "metadata": {},
   "source": [
    "# /Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1264c05e-808d-4c7b-9c8d-22fdb88651e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_DISTANCE=1.3\n",
    "K=10\n",
    "\n",
    "def _build_context(query_result: QueryResult, min_distance:float)->str:\n",
    "    documents = query_result.documents[0]\n",
    "    distances = query_result.distances[0]\n",
    "    context = [\"Here are some notes from previous conversations between you and the user that might be relevant to you. Note that this snippets are from conversations that happened in the past.\"]\n",
    "    context_num = 1\n",
    "    seen_contexts = set() # to handle exact duplicates that could inadvertedly be in the index\n",
    "    for document, distance in zip(documents, distances):\n",
    "        if distance < min_distance and document not in seen_contexts:\n",
    "            context.append(f\"{context_num}: {document}\")\n",
    "            context_num += 1\n",
    "            seen_contexts.add(document)\n",
    "    return \"\\n\".join(context)\n",
    "\n",
    "\n",
    "def retrieve(content_to_retrieve:str, min_distance:float=MIN_DISTANCE, k:int=K):\n",
    "    query_result = query_index(\n",
    "        query_texts=[content_to_retrieve],\n",
    "        n_results=k\n",
    "    )\n",
    "    return _build_context(query_result, min_distance)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77db495-2404-479d-bcd4-a8a09e8d18bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some notes from previous conversations between you and the user that might be relevant to you. Note that this snippets are from conversations that happened in the past.\n",
      "1: User is thinking of starting a course in data science.\n",
      "2: User plans to start the data science course tomorrow.\n",
      "3: User is considering a career change.\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "retrieval_result = retrieve(\"when is the user going to start a course?\")\n",
    "print(retrieval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b63e730-6b32-4343-9159-ba0e9036bee7",
   "metadata": {},
   "source": [
    "# /Recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447eddc4-4281-461e-a7e2-25dea725cb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recap():\n",
    "    return current_knowledge.knowledge\n",
    "\n",
    "UPDATE_KNOWLEDGE_PROMPT = \"\"\"\\\n",
    "You are a career confidante. Given a conversation that just happened between you and the user, and your current knowledge of the user, update your knowledge of the user.\n",
    "In your updated knowledge, you should include useful information for future interactions with the user.\n",
    "The conversation just happened, so you should integrate the new information from the conversation into your updated knowledge. \n",
    "\n",
    "Return only the updated knowledge in JSON format.\n",
    "\n",
    "The conversation is as follows:\n",
    "{conversation}\n",
    "\n",
    "Your current knowledge of the user is as follows:\n",
    "{knowledge}\n",
    "\n",
    "Response Format:\n",
    "{{\n",
    "    \"knowledge\": \"Updated knowledge of the user.\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "def update_knowledge(user_messages:list[str], assistant_messages:list[str], current_knowledge: CurrentKnowledge):\n",
    "    conversation = _construct_conversation(user_messages, assistant_messages)\n",
    "    prompt = UPDATE_KNOWLEDGE_PROMPT.format(conversation=conversation, knowledge=current_knowledge)\n",
    "    current_knowledge: CurrentKnowledge = chat_completion_request(\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_model=CurrentKnowledge\n",
    "    )\n",
    "    return current_knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd46ab-4644-4647-88bb-ded11e5e962e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knowledge='The user has recently been laid off from their job and is considering a career change. They are interested in data science and plan to start a course in this field tomorrow.'\n",
      "knowledge='The user has found a new job. They were recently laid off and were considering a career change, with an interest in data science. They planned to start a course in data science, but it is unclear if they have started or completed it. Future interactions should explore their new job role, satisfaction with the position, and whether they are still pursuing data science education or career change.'\n"
     ]
    }
   ],
   "source": [
    "current_knowledge = update_knowledge(\n",
    "    user_messages=[\"I just got laid off from my job.\", \"I am considering a career change.\", \"First, I am thinking of starting a course in data science.\", \"tomorrow\"],\n",
    "    assistant_messages=[\"What are you considering?\", \"What are your interests?\", \"When do you plan to start the course?\", \"That's great!\"],\n",
    "    current_knowledge=current_knowledge\n",
    ")\n",
    "print(current_knowledge)\n",
    "\n",
    "current_knowledge = update_knowledge(\n",
    "    user_messages=[\"I have found a job.\"],\n",
    "    assistant_messages=[\"That's great!\"],\n",
    "    current_knowledge=current_knowledge\n",
    ")\n",
    "print(current_knowledge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b45aaf2-fe86-43a7-bc2a-09d7cd0b8c5e",
   "metadata": {},
   "source": [
    "- Recap function\n",
    "- Prompt for context after recap/ retrieve\n",
    "- Prompt for context after receive has to include sorting on memories.\n",
    "- Need to include time of insertion?\n",
    "- Managing memory\n",
    "\n",
    "\n",
    "/retrieve\n",
    "- has to include date of event if available\n",
    "- [optional] probably needs to include a sorted order of ingestion time?\n",
    "\n",
    "/store \n",
    "- needs a way to modify memories. The idea is probably to provide a list of IDs and similar documents. Then ask it what we need to combine/update. \n",
    "- returns 2 fields (to_add, to_delete). They are lists of DocumentNode objects. (thinking that update can be replaced by add and delete functions.)\n",
    "- need to find a nice way to prompt \n",
    "\n",
    "\n",
    "[Optional]\n",
    "- Actively pushing events.\n",
    "- conversation chaining\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
