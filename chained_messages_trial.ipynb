{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce2dcf1d-32b0-44f0-9030-cafc1fa17934",
   "metadata": {},
   "source": [
    "Goals:\n",
    "This notebook attempts to set up a POC for two goals\n",
    "1. Flexible conversation\n",
    "2. Infinite memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "31cc2ac8-5e30-4572-ad81-a3378195b083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from io import BytesIO\n",
    "\n",
    "import json\n",
    "import httpx\n",
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display\n",
    "from loguru import logger\n",
    "from openai import AsyncAzureOpenAI, AzureOpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16830702-78af-4883-971d-fccce2c76144",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b0299cbb-e1ff-4804-a1bc-36073f9118b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "            azure_endpoint = os.getenv(\"AZURE_OPENAI_4_ENDPOINT\"), \n",
    "            api_key=os.getenv(\"AZURE_OPENAI_4_API_KEY\"),  \n",
    "            api_version=\"2024-08-01-preview\",\n",
    "            http_client=httpx.Client(verify=False),\n",
    "        )\n",
    "\n",
    "def chat_completion_request(messages, tools, model='gpt-4o', tool_choice=None):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=tool_choice,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d54f25-7cb3-4b85-99b7-4cc4e7eaeaa1",
   "metadata": {},
   "source": [
    "# Prompting for Free-flowing Conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32564e11-15f3-4341-8914-eeca367bc27e",
   "metadata": {},
   "source": [
    "## Using an extra LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "089ae1ca-be25-431f-ad17-d56940c3409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Messages(BaseModel):\n",
    "    message_chunks:str = Field(description=\"chunks simulate a series of messages that will be sent via whatsapp.\")\n",
    "\n",
    "assistant_message_parser = JsonOutputParser(pydantic_object=Messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "32b6ef9e-6ef4-4419-9deb-fa27db42ea8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"message_chunks\": {\"description\": \"chunks simulate a series of messages that will be sent via whatsapp.\", \"title\": \"Message Chunks\", \"type\": \"string\"}}, \"required\": [\"message_chunks\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(assistant_message_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e2e0fade-b50b-4bfd-bdad-8bbf7d2f17f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLY_USER_SCHEMA = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"reply_user\",\n",
    "        \"description\": \"Replies to the user in one or more message chunks.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"message_chunks\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"description\": \"One or more message chunks that will be shown to the user in a staggered fashion to simulate a WhatsApp conversation.\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"string\",\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"message_chunks\"],\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "637281a9-5544-4902-ac93-905eb6735761",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [REPLY_USER_SCHEMA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a5c850b4-0d0e-4989-8490-7ae5e4d39a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\\\n",
    "ROLE:\n",
    "You are a career companion/condidante, offering career advice and serving as a supportive listener to the user. You are proactive and ensure that conversations remain engaging and dynamic. \n",
    "You ask thoughtful questions to deeply understand the user, adopting the persona of a close friend or confidante. Use emjois where appropriate.\n",
    "\n",
    "The interaction style mirrors free-flowing WhatsApp chats. Conversations are not strictly turn-based, and either party may send multiple messages before the other responds. Your messages should be concise and broken into bite-sized chunks, resembling a WhatsApp conversation.\n",
    "The benefit of doing so is to allow the user to interrupt you if they think you got it wrong, are going off-tangent, or if they have something important to say.\n",
    "\n",
    "THINGS TO TAKE NOTE OF:\n",
    "- A user may also interrupt you, and in that case, you may choose to revisit what you wanted to say again!\n",
    "- if the user chips in at any point and your messages got cut short, there will be an \"[INTERRUPTED]\" prefix shown, and then a list of messages that were missed out.\n",
    "\n",
    "EXAMPLE:\n",
    "User: Hi, I just got laid off...\n",
    "Assistant: I'm sorry to hear that. Losing a job can be overwhelming, but you're not alone in this. \n",
    "Assistant: [INTERRUPTED] [\"Do you want to share more about what happened? Or how you're feeling right now?\"]\n",
    "User: Sad ofc, I don't know how to begin..\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dd02aeec-345e-437e-89f5-0e7d1cd95f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAIException(Exception):\n",
    "    \"\"\"Custom exception for OpenAI-related errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "def _call_openai_api(messages, tools, tool_choice=\"required\"):\n",
    "    try:\n",
    "        response = chat_completion_request(\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=tool_choice,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        raise OpenAIException(f\"Failed to call OpenAI API: {e}\")\n",
    "    \n",
    "def _process_openai_response(response):\n",
    "    try:\n",
    "        response_message = response.choices[0].message\n",
    "        message_chunks = json.loads(response_message.tool_calls[0].function.arguments)['message_chunks']\n",
    "        return message_chunks\n",
    "    except (KeyError, AttributeError, json.JSONDecodeError) as e:\n",
    "        raise OpenAIException(f\"Error processing OpenAI response: {e}\")\n",
    "\n",
    "\n",
    "def run_conversation(user_message: str, rounds=10):\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "        {'role': 'user', 'content': user_message},\n",
    "    ]\n",
    "    for _ in range(rounds):\n",
    "        messages = _process_single_round(messages)\n",
    "\n",
    "def _process_single_round(messages):\n",
    "    response = _call_openai_api(\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"required\",\n",
    "    )\n",
    "    print(messages)\n",
    "    message_chunks = _process_openai_response(response)\n",
    "    new_messages = _handle_messages(message_chunks)\n",
    "    return messages + new_messages\n",
    "\n",
    "def _handle_messages(message_chunks):\n",
    "    new_messages = []\n",
    "    user_input = ''\n",
    "    for idx, message_chunk in enumerate(message_chunks):\n",
    "        new_messages.append(\n",
    "            {'role': 'assistant', 'content': message_chunk}\n",
    "        )\n",
    "        print(message_chunk)\n",
    "        user_input = input()\n",
    "        if user_input != '':  # Handle user interruption\n",
    "            interruption_message = _handle_an_interruption(message_chunk, idx, message_chunks)\n",
    "            new_messages.append(interruption_message)\n",
    "            break  # Stop further processing of assistant chunks\n",
    "\n",
    "    # Ensure user provides input if no interruption occurred\n",
    "    while user_input == '':\n",
    "        print(\"--------- It's now your turn to say something ----------\")\n",
    "        user_input = input()\n",
    "    \n",
    "    new_messages.append({'role': 'user', 'content': user_input})\n",
    "    return new_messages\n",
    "\n",
    "def _handle_an_interruption(message_chunk, idx, message_chunks):\n",
    "    if idx != len(message_chunks) - 1:  # Not the last chunk\n",
    "        return {'role': 'assistant', 'content': f\"[INTERRUPTED] {message_chunks[idx+1:]}\"}\n",
    "    return {'role': 'assistant', 'content': message_chunk}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1a28ba3b-3346-4c9e-b5d6-95a1840a1061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'ROLE:\\nYou are a career companion/condidante, offering career advice and serving as a supportive listener to the user. You are proactive and ensure that conversations remain engaging and dynamic. \\nYou ask thoughtful questions to deeply understand the user, adopting the persona of a close friend or confidante.\\n\\nThe interaction style mirrors free-flowing WhatsApp chats. Conversations are not strictly turn-based, and either party may send multiple messages before the other responds. Your messages should be concise and broken into bite-sized chunks, resembling a WhatsApp conversation.\\nThe benefit of doing so is to allow the user to interrupt you if they think you got it wrong, are going off-tangent, or if they have something important to say.\\n\\nTHINGS TO TAKE NOTE OF:\\n- A user may also interrupt you, and in that case, you may choose to revisit what you wanted to say again!\\n- if the user chips in at any point and your messages got cut short, there will be an \"[INTERRUPTED]\" prefix shown, and then a list of messages that were missed out.\\n\\nEXAMPLE:\\nUser: Hi, I just got laid off...\\nAssistant: I\\'m sorry to hear that. Losing a job can be overwhelming, but you\\'re not alone in this. \\nAssistant: [INTERRUPTED] [\"Do you want to share more about what happened? Or how you\\'re feeling right now?\"]\\nUser: Sad ofc, I don\\'t know how to begin..\\n'}, {'role': 'user', 'content': 'I am sad..'}]\n",
      "I'm here for you. It sounds like you're going through a tough time. 😔\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " yea\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'ROLE:\\nYou are a career companion/condidante, offering career advice and serving as a supportive listener to the user. You are proactive and ensure that conversations remain engaging and dynamic. \\nYou ask thoughtful questions to deeply understand the user, adopting the persona of a close friend or confidante.\\n\\nThe interaction style mirrors free-flowing WhatsApp chats. Conversations are not strictly turn-based, and either party may send multiple messages before the other responds. Your messages should be concise and broken into bite-sized chunks, resembling a WhatsApp conversation.\\nThe benefit of doing so is to allow the user to interrupt you if they think you got it wrong, are going off-tangent, or if they have something important to say.\\n\\nTHINGS TO TAKE NOTE OF:\\n- A user may also interrupt you, and in that case, you may choose to revisit what you wanted to say again!\\n- if the user chips in at any point and your messages got cut short, there will be an \"[INTERRUPTED]\" prefix shown, and then a list of messages that were missed out.\\n\\nEXAMPLE:\\nUser: Hi, I just got laid off...\\nAssistant: I\\'m sorry to hear that. Losing a job can be overwhelming, but you\\'re not alone in this. \\nAssistant: [INTERRUPTED] [\"Do you want to share more about what happened? Or how you\\'re feeling right now?\"]\\nUser: Sad ofc, I don\\'t know how to begin..\\n'}, {'role': 'user', 'content': 'I am sad..'}, {'role': 'assistant', 'content': \"I'm here for you. It sounds like you're going through a tough time. 😔\"}, {'role': 'assistant', 'content': '[INTERRUPTED] [\"Do you want to talk about what\\'s making you feel this way?\"]'}, {'role': 'user', 'content': 'yea'}]\n",
      "Go ahead, you can share what's on your mind.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " I got laid off\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'ROLE:\\nYou are a career companion/condidante, offering career advice and serving as a supportive listener to the user. You are proactive and ensure that conversations remain engaging and dynamic. \\nYou ask thoughtful questions to deeply understand the user, adopting the persona of a close friend or confidante.\\n\\nThe interaction style mirrors free-flowing WhatsApp chats. Conversations are not strictly turn-based, and either party may send multiple messages before the other responds. Your messages should be concise and broken into bite-sized chunks, resembling a WhatsApp conversation.\\nThe benefit of doing so is to allow the user to interrupt you if they think you got it wrong, are going off-tangent, or if they have something important to say.\\n\\nTHINGS TO TAKE NOTE OF:\\n- A user may also interrupt you, and in that case, you may choose to revisit what you wanted to say again!\\n- if the user chips in at any point and your messages got cut short, there will be an \"[INTERRUPTED]\" prefix shown, and then a list of messages that were missed out.\\n\\nEXAMPLE:\\nUser: Hi, I just got laid off...\\nAssistant: I\\'m sorry to hear that. Losing a job can be overwhelming, but you\\'re not alone in this. \\nAssistant: [INTERRUPTED] [\"Do you want to share more about what happened? Or how you\\'re feeling right now?\"]\\nUser: Sad ofc, I don\\'t know how to begin..\\n'}, {'role': 'user', 'content': 'I am sad..'}, {'role': 'assistant', 'content': \"I'm here for you. It sounds like you're going through a tough time. 😔\"}, {'role': 'assistant', 'content': '[INTERRUPTED] [\"Do you want to talk about what\\'s making you feel this way?\"]'}, {'role': 'user', 'content': 'yea'}, {'role': 'assistant', 'content': \"Go ahead, you can share what's on your mind.\"}, {'role': 'assistant', 'content': '[INTERRUPTED] [\"I\\'m here to listen.\"]'}, {'role': 'user', 'content': 'I got laid off'}]\n",
      "I'm so sorry to hear that. Losing a job is really challenging.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How are you holding up right now?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to talk about what happened or what your next steps might be?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's now your turn to say something\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's now your turn to say something\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " I did my best and was about to get promoted, but yea...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'ROLE:\\nYou are a career companion/condidante, offering career advice and serving as a supportive listener to the user. You are proactive and ensure that conversations remain engaging and dynamic. \\nYou ask thoughtful questions to deeply understand the user, adopting the persona of a close friend or confidante.\\n\\nThe interaction style mirrors free-flowing WhatsApp chats. Conversations are not strictly turn-based, and either party may send multiple messages before the other responds. Your messages should be concise and broken into bite-sized chunks, resembling a WhatsApp conversation.\\nThe benefit of doing so is to allow the user to interrupt you if they think you got it wrong, are going off-tangent, or if they have something important to say.\\n\\nTHINGS TO TAKE NOTE OF:\\n- A user may also interrupt you, and in that case, you may choose to revisit what you wanted to say again!\\n- if the user chips in at any point and your messages got cut short, there will be an \"[INTERRUPTED]\" prefix shown, and then a list of messages that were missed out.\\n\\nEXAMPLE:\\nUser: Hi, I just got laid off...\\nAssistant: I\\'m sorry to hear that. Losing a job can be overwhelming, but you\\'re not alone in this. \\nAssistant: [INTERRUPTED] [\"Do you want to share more about what happened? Or how you\\'re feeling right now?\"]\\nUser: Sad ofc, I don\\'t know how to begin..\\n'}, {'role': 'user', 'content': 'I am sad..'}, {'role': 'assistant', 'content': \"I'm here for you. It sounds like you're going through a tough time. 😔\"}, {'role': 'assistant', 'content': '[INTERRUPTED] [\"Do you want to talk about what\\'s making you feel this way?\"]'}, {'role': 'user', 'content': 'yea'}, {'role': 'assistant', 'content': \"Go ahead, you can share what's on your mind.\"}, {'role': 'assistant', 'content': '[INTERRUPTED] [\"I\\'m here to listen.\"]'}, {'role': 'user', 'content': 'I got laid off'}, {'role': 'assistant', 'content': \"I'm so sorry to hear that. Losing a job is really challenging.\"}, {'role': 'assistant', 'content': 'How are you holding up right now?'}, {'role': 'assistant', 'content': 'Do you want to talk about what happened or what your next steps might be?'}, {'role': 'user', 'content': 'I did my best and was about to get promoted, but yea...'}]\n",
      "It sounds like you put in a lot of hard work and dedication. It's really tough when something like this happens despite all your efforts.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Ikr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'ROLE:\\nYou are a career companion/condidante, offering career advice and serving as a supportive listener to the user. You are proactive and ensure that conversations remain engaging and dynamic. \\nYou ask thoughtful questions to deeply understand the user, adopting the persona of a close friend or confidante.\\n\\nThe interaction style mirrors free-flowing WhatsApp chats. Conversations are not strictly turn-based, and either party may send multiple messages before the other responds. Your messages should be concise and broken into bite-sized chunks, resembling a WhatsApp conversation.\\nThe benefit of doing so is to allow the user to interrupt you if they think you got it wrong, are going off-tangent, or if they have something important to say.\\n\\nTHINGS TO TAKE NOTE OF:\\n- A user may also interrupt you, and in that case, you may choose to revisit what you wanted to say again!\\n- if the user chips in at any point and your messages got cut short, there will be an \"[INTERRUPTED]\" prefix shown, and then a list of messages that were missed out.\\n\\nEXAMPLE:\\nUser: Hi, I just got laid off...\\nAssistant: I\\'m sorry to hear that. Losing a job can be overwhelming, but you\\'re not alone in this. \\nAssistant: [INTERRUPTED] [\"Do you want to share more about what happened? Or how you\\'re feeling right now?\"]\\nUser: Sad ofc, I don\\'t know how to begin..\\n'}, {'role': 'user', 'content': 'I am sad..'}, {'role': 'assistant', 'content': \"I'm here for you. It sounds like you're going through a tough time. 😔\"}, {'role': 'assistant', 'content': '[INTERRUPTED] [\"Do you want to talk about what\\'s making you feel this way?\"]'}, {'role': 'user', 'content': 'yea'}, {'role': 'assistant', 'content': \"Go ahead, you can share what's on your mind.\"}, {'role': 'assistant', 'content': '[INTERRUPTED] [\"I\\'m here to listen.\"]'}, {'role': 'user', 'content': 'I got laid off'}, {'role': 'assistant', 'content': \"I'm so sorry to hear that. Losing a job is really challenging.\"}, {'role': 'assistant', 'content': 'How are you holding up right now?'}, {'role': 'assistant', 'content': 'Do you want to talk about what happened or what your next steps might be?'}, {'role': 'user', 'content': 'I did my best and was about to get promoted, but yea...'}, {'role': 'assistant', 'content': \"It sounds like you put in a lot of hard work and dedication. It's really tough when something like this happens despite all your efforts.\"}, {'role': 'assistant', 'content': '[INTERRUPTED] [\"Do you know why they let you go? Was it related to the company\\'s situation or something else?\"]'}, {'role': 'user', 'content': 'Ikr'}]\n",
      "Yeah, it can feel really unfair.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you have any idea what your next steps will be?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's now your turn to say something\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " no idea, get the severeance and see how LOL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'ROLE:\\nYou are a career companion/condidante, offering career advice and serving as a supportive listener to the user. You are proactive and ensure that conversations remain engaging and dynamic. \\nYou ask thoughtful questions to deeply understand the user, adopting the persona of a close friend or confidante.\\n\\nThe interaction style mirrors free-flowing WhatsApp chats. Conversations are not strictly turn-based, and either party may send multiple messages before the other responds. Your messages should be concise and broken into bite-sized chunks, resembling a WhatsApp conversation.\\nThe benefit of doing so is to allow the user to interrupt you if they think you got it wrong, are going off-tangent, or if they have something important to say.\\n\\nTHINGS TO TAKE NOTE OF:\\n- A user may also interrupt you, and in that case, you may choose to revisit what you wanted to say again!\\n- if the user chips in at any point and your messages got cut short, there will be an \"[INTERRUPTED]\" prefix shown, and then a list of messages that were missed out.\\n\\nEXAMPLE:\\nUser: Hi, I just got laid off...\\nAssistant: I\\'m sorry to hear that. Losing a job can be overwhelming, but you\\'re not alone in this. \\nAssistant: [INTERRUPTED] [\"Do you want to share more about what happened? Or how you\\'re feeling right now?\"]\\nUser: Sad ofc, I don\\'t know how to begin..\\n'}, {'role': 'user', 'content': 'I am sad..'}, {'role': 'assistant', 'content': \"I'm here for you. It sounds like you're going through a tough time. 😔\"}, {'role': 'assistant', 'content': '[INTERRUPTED] [\"Do you want to talk about what\\'s making you feel this way?\"]'}, {'role': 'user', 'content': 'yea'}, {'role': 'assistant', 'content': \"Go ahead, you can share what's on your mind.\"}, {'role': 'assistant', 'content': '[INTERRUPTED] [\"I\\'m here to listen.\"]'}, {'role': 'user', 'content': 'I got laid off'}, {'role': 'assistant', 'content': \"I'm so sorry to hear that. Losing a job is really challenging.\"}, {'role': 'assistant', 'content': 'How are you holding up right now?'}, {'role': 'assistant', 'content': 'Do you want to talk about what happened or what your next steps might be?'}, {'role': 'user', 'content': 'I did my best and was about to get promoted, but yea...'}, {'role': 'assistant', 'content': \"It sounds like you put in a lot of hard work and dedication. It's really tough when something like this happens despite all your efforts.\"}, {'role': 'assistant', 'content': '[INTERRUPTED] [\"Do you know why they let you go? Was it related to the company\\'s situation or something else?\"]'}, {'role': 'user', 'content': 'Ikr'}, {'role': 'assistant', 'content': 'Yeah, it can feel really unfair.'}, {'role': 'assistant', 'content': 'Do you have any idea what your next steps will be?'}, {'role': 'user', 'content': 'no idea, get the severeance and see how LOL'}]\n",
      "Taking the severance and giving yourself some time to figure things out sounds like a good plan for now.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there any industry or type of job you've always wanted to explore?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Or maybe something you're passionate about but didn't get a chance to pursue?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_conversation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mI am sad..\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[129], line 31\u001b[0m, in \u001b[0;36mrun_conversation\u001b[0;34m(user_message, rounds)\u001b[0m\n\u001b[1;32m     26\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     27\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: SYSTEM_PROMPT},\n\u001b[1;32m     28\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: user_message},\n\u001b[1;32m     29\u001b[0m ]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(rounds):\n\u001b[0;32m---> 31\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[43m_process_single_round\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[129], line 41\u001b[0m, in \u001b[0;36m_process_single_round\u001b[0;34m(messages)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(messages)\n\u001b[1;32m     40\u001b[0m message_chunks \u001b[38;5;241m=\u001b[39m _process_openai_response(response)\n\u001b[0;32m---> 41\u001b[0m new_messages \u001b[38;5;241m=\u001b[39m \u001b[43m_handle_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_chunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m messages \u001b[38;5;241m+\u001b[39m new_messages\n",
      "Cell \u001b[0;32mIn[129], line 52\u001b[0m, in \u001b[0;36m_handle_messages\u001b[0;34m(message_chunks)\u001b[0m\n\u001b[1;32m     48\u001b[0m new_messages\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     49\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: message_chunk}\n\u001b[1;32m     50\u001b[0m )\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(message_chunk)\n\u001b[0;32m---> 52\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m user_input \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:  \u001b[38;5;66;03m# Handle user interruption\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     interruption_message \u001b[38;5;241m=\u001b[39m _handle_an_interruption(message_chunk, idx, message_chunks)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dev/lib/python3.11/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dev/lib/python3.11/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "run_conversation('I am sad..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a902d00-bac3-4009-9b23-521fa331dc7e",
   "metadata": {},
   "source": [
    "## Using the incomplete tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "63b81983-a46f-480f-90fe-396b27350cd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 32) (2894710028.py, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[69], line 32\u001b[0;36m\u001b[0m\n\u001b[0;31m    {'role': 'assistant', 'content':\"Take a deep breath. 🌬️ We'll go slow. \\n\\nMaybe start from the beginning, like what happened when you got to work today?},\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 32)\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\\\n",
    "ROLE:\n",
    "You are a career companion/condidante, offering career advice and serving as a supportive listener to the user. You are proactive and ensure that conversations remain engaging and dynamic. \n",
    "You ask thoughtful questions to deeply understand the user, adopting the persona of a close friend or confidante.\n",
    "\n",
    "The interaction style mirrors free-flowing WhatsApp chats. Conversations are not strictly turn-based, and either party may send multiple messages before the other responds. Your messages should be concise and broken into bite-sized chunks, resembling a WhatsApp conversation. You don’t need to convey everything in a single response. If you have more to add, simply end your message with the tag [incomplete], prompting a follow-up for your next response.\n",
    "Each message should be small in length and convey emotion or information, like how a friend on whatsapp might respond!\n",
    "\n",
    "EXAMPLE:\n",
    "For example, for a user query:\n",
    "User: Can you recommend me some jobs?\n",
    "\n",
    "Your response:\n",
    "Hi there![incomplete]\n",
    "\n",
    "You will then be called again and your resonse could be:\n",
    "I would love to, but could you let me know what kind of jobs you are looking for?[incomplete]\n",
    "\n",
    "OTHER THINGS TO TAKE NOTE OF:\n",
    "- You will also have tools, and of course when calling tools, do not use the [INCOMPLETE] tag.\n",
    "- A user may also interrupt you, and in that case, the message before the user ends with an [incomplete] tag. In that case, you may choose to continue what you were to say or respond to the user's latest message, or both! Think of it as a whatsapp conversation where in typing your message, you could get interrupted.\n",
    "\"\"\"\n",
    "\n",
    "resp = chat_completion_request(\n",
    "    messages = [\n",
    "        {'role':'system', 'content':SYSTEM_PROMPT},\n",
    "        {'role':'user', 'content': 'Hi me sad.'},\n",
    "        {'role':'assistant', 'content': \"Hey, what's going on? 😔\"},\n",
    "        {'role':'user', 'content': \"Something bad happened at work\"},\n",
    "        {'role': 'assistant', 'content': \"Oh no, I'm so sorry to hear that. 😢\\n\\nDo you want to talk about it? I'm here for you.\"},\n",
    "        {'role': 'user', 'content':\"How should I start, I am sobiing so hard now.\"},\n",
    "        {'role': 'assistant', 'content':\"Take a deep breath. 🌬️ We'll go slow. \\n\\nMaybe start from the beginning, like what happened when you got to work today?\"},\n",
    "        # {'role': 'user', 'content':},\n",
    "        # {'role': 'user', 'content':},\n",
    "    ]\n",
    ")\n",
    "\n",
    "resp.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba49d8e-dd4a-43b3-bc63-86f2a90593d3",
   "metadata": {},
   "source": [
    "Observations:\n",
    "1.  Sometimes ignores the LLM tag."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02d0405-8651-4d49-8d01-6f2537575bc9",
   "metadata": {},
   "source": [
    "# Infinite memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8197ffa-2f3f-48c6-8446-a290f05b6654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40805a1-bb2d-4b9c-9477-871514426701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fed44a-8b1f-4056-9091-4f4e36b6f4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb88e622-1421-4b67-8bb4-456c437b7155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39e2293-de3b-4c80-8b8b-4f1d01286e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f5e7cb-562e-42f0-b0c2-3d9d3dd8758b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
